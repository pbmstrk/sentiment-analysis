{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "sentiment-analysis-sst",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COyy_lTb4bSn"
      },
      "source": [
        "# Sentiment Analysis (Stanford Sentiment Treebank)\n",
        "\n",
        "---\n",
        "\n",
        "**Various models for sentiment analysis on Stanford Sentiment Treebank dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRXJJq556aeE",
        "outputId": "9c7f3d26-4243-4e32-b57b-511de6948523",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        }
      },
      "source": [
        "!pip install pytorch-lightning -q"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 409kB 9.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 829kB 19.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 276kB 29.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.8MB 46.8MB/s \n",
            "\u001b[?25h  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for PyYAML (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: tensorflow 2.3.0 has requirement tensorboard<3,>=2.3.0, but you'll have tensorboard 2.2.0 which is incompatible.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLBtQm_0qabd"
      },
      "source": [
        "# import necessary modules\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import torchtext\n",
        "\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import pytorch_lightning as pl\n",
        "\n",
        "from pytorch_lightning import Trainer\n",
        "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.nn.utils.rnn import (pad_sequence, pack_padded_sequence, \n",
        "                                  pad_packed_sequence)\n",
        "\n",
        "from collections import namedtuple, Counter"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqBqEH2l5ARf"
      },
      "source": [
        "## Multi-Layer Perceptron\n",
        "\n",
        "The first model is based on an architecture presented in the paper, [Bag of Tricks for Efficient Text Classification](https://www.aclweb.org/anthology/E17-2068/). In particular, we use a Multi-Layer Perceptron (MLP) to predict sentiment using an aggregated representation of the input. The input is tokenized into individual words, and each word is then represented by its embedding. Inputs can be of different length, thus, the embeddings are aggregated by the use of a pooling function (often mean-pooling - that is, simply the element-wise mean) to create a fixed-size representation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OiwvhtUcM8oB"
      },
      "source": [
        "Our implementation differs slightly from the presentation in the paper, since we make use of pre-trained word embeddings and do not implement a hierarchical softmax. Regarding the use of embeddings, there are two options: (1) keep the pre-trained embeddings fixed during training, and (2) include the embeddings in the optimisation. In our implementation we choose to optimise the embeddings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RVu0arV47Et"
      },
      "source": [
        "### Pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UjTuj0n1xIw"
      },
      "source": [
        "# use a named-tuple to store data examples\n",
        "Example = namedtuple(\"Example\", [\"text\", \"label\"])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2oKrI4LQTMW"
      },
      "source": [
        "class SST_Dataset(Dataset):\n",
        "    \n",
        "    def __init__(self, dataset):\n",
        "        self.dataset = dataset\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "    \n",
        "    def __getitem__(self, idx): \n",
        "        element = self.dataset[idx] \n",
        "        X = element.text\n",
        "        Y = element.label\n",
        "        return X, Y"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAQRDySoQTSR"
      },
      "source": [
        "class SSTDataModuleBase(pl.LightningDataModule):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.PAD_token = 0\n",
        "        self.UNK_token = 1\n",
        "        self.SOS_token = 2\n",
        "        self.EOS_token = 3\n",
        "\n",
        "        self.targetEncoding = {'negative': 0, 'positive': 1}\n",
        "        \n",
        "    \n",
        "    def _format_data(self, dataset):\n",
        "        \n",
        "        tokenized_dataset = []\n",
        "        for element in dataset:\n",
        "            encoding = self._tokenize(element)\n",
        "            tokenized_dataset.append(Example(text=encoding[0], label=encoding[1]))\n",
        "\n",
        "        return tokenized_dataset\n",
        "\n",
        "\n",
        "    def embedding_matrix(self):\n",
        "\n",
        "        glove = torchtext.vocab.GloVe(name='6B', dim=300, \n",
        "                                      unk_init = torch.Tensor.normal_)\n",
        "        matrix_len = len(self._wordlist)\n",
        "        weights_matrix = np.zeros((matrix_len, 300))\n",
        "\n",
        "        for i, word in enumerate(self._wordlist):\n",
        "            try: \n",
        "                weights_matrix[i] = glove.vectors[glove.stoi[word]]\n",
        "            except KeyError:\n",
        "                weights_matrix[i] = np.random.normal(scale=0.5, size=(300, ))\n",
        "\n",
        "        return weights_matrix   \n",
        "\n",
        "    @staticmethod\n",
        "    def _flatten(lst):\n",
        "        return [item for sublist in lst for item in sublist]\n",
        "        \n",
        "    def _build_vocab(self, data):\n",
        "        vocab_counter = Counter(self._flatten([example.text for example in data]))\n",
        "        return vocab_counter\n",
        "\n",
        "\n",
        "    def _build_encoding(self, vocab_count, min_freq=3):\n",
        "\n",
        "        self._wordlist = [\"<PAD>\", \"<UNK>\", \"<SOS>\", \"<EOS>\"]\n",
        "        self.encoding = {}\n",
        "\n",
        "        svocabCount = {k: v for k, v in reversed(sorted(vocab_count.items(), \n",
        "                                        key=lambda item: item[1]))}\n",
        "\n",
        "        for word in svocabCount:\n",
        "            if svocabCount[word] >= min_freq:\n",
        "                self._wordlist.append(word)\n",
        "        self.encoding.update({tok: i for i, tok in enumerate(self._wordlist)})\n",
        "        \n",
        "    def _tokenize(self, element):\n",
        "\n",
        "        text = (torch.tensor([self.SOS_token] + \n",
        "          [self.encoding.get(word, self.UNK_token) for word in element.text] + \n",
        "          [self.EOS_token]))\n",
        "        label = torch.tensor(self.targetEncoding[element.label])\n",
        "\n",
        "        return text, label  \n",
        "\n",
        "    def setup(self, stage=None, min_freq=3):\n",
        "\n",
        "        TEXT = torchtext.data.Field(tokenize='spacy', lower=True)\n",
        "        LABEL = torchtext.data.Field(sequential=False)\n",
        "        \n",
        "        train_data, val_data, test_data = torchtext.datasets.SST.splits(TEXT, \n",
        "          LABEL, filter_pred=lambda ex: ex.label != 'neutral', train_subtrees=True)\n",
        "        \n",
        "      \n",
        "        vocab_counter = self._build_vocab(train_data)\n",
        "        self._build_encoding(vocab_counter, min_freq)\n",
        "\n",
        "        if stage == 'fit' or stage is None:\n",
        "            self.sst_train = SST_Dataset(self._format_data(train_data))\n",
        "            self.sst_val = SST_Dataset(self._format_data(val_data))\n",
        "\n",
        "\n",
        "        if stage == 'test' or stage is None:\n",
        "            self.sst_test = SST_Dataset(self._format_data(test_data))\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        raise NotImplementedError\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQ7TL-UhVjYd"
      },
      "source": [
        "class SSTDataModuleMLP(SSTDataModuleBase):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    @staticmethod\n",
        "    def _collate_fn(batch):\n",
        "        # get data and targets from batch\n",
        "        data = [item[0] for item in batch]\n",
        "        targets = [item[1] for item in batch]\n",
        "        lengths = [len(el) for el in data]\n",
        "        offsets = np.cumsum(lengths)\n",
        "        offsets = np.concatenate([[0], offsets[:-1]])\n",
        "\n",
        "        return (torch.LongTensor(torch.cat(data).long()), \n",
        "                torch.Tensor(targets).float(), \n",
        "                torch.LongTensor(offsets))\n",
        "        \n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(self.sst_train, batch_size=64, \n",
        "                              collate_fn=self._collate_fn, shuffle=True)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(self.sst_val, batch_size=64, \n",
        "                              collate_fn=self._collate_fn)\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return DataLoader(self.sst_test, batch_size=64,\n",
        "                              collate_fn=self._collate_fn)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bYhcmGODOZ2"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRXfntQODbGv",
        "outputId": "99ded015-bf02-4913-d71e-002c56cf96d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        }
      },
      "source": [
        "ds = SSTDataModuleMLP()\n",
        "ds.setup(min_freq=3)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "downloading trainDevTestTrees_PTB.zip\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "trainDevTestTrees_PTB.zip: 100%|██████████| 790k/790k [00:01<00:00, 500kB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "extracting\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IrXKE6qy5587"
      },
      "source": [
        "class FastText(pl.LightningModule):\n",
        "    \n",
        "    def __init__(self, input_size, embed_mat=None):\n",
        "        \n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding = nn.EmbeddingBag(input_size, 300, mode=\"mean\")\n",
        "        if embed_mat is not None:\n",
        "            self.embedding = self.embedding.from_pretrained(torch.from_numpy(embed_mat).float())\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(300, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(256, 1),\n",
        "        )\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=0.0001, \n",
        "                                     weight_decay=1e-05)\n",
        "        return optimizer\n",
        "\n",
        "    def forward(self, batch):\n",
        "\n",
        "        inputs, _, offsets = batch\n",
        "        # inputs: [SUM(SEQ_LENGTHS)]\n",
        "\n",
        "        x = self.embedding(inputs, offsets)\n",
        "        # x: [BATCH_SIZE, EMBED_DIM]\n",
        "\n",
        "        x = self.fc(x).squeeze()\n",
        "        # x: [BATCH_SIZE]\n",
        "        \n",
        "        return x\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "\n",
        "        x, y, offsets = batch\n",
        "        y_hat = self(batch)\n",
        "\n",
        "        # compute loss\n",
        "        loss = F.binary_cross_entropy_with_logits(y_hat, y)\n",
        "\n",
        "        return {'loss': loss, \n",
        "                \"batch_size\": len(y)}\n",
        "\n",
        "    def training_epoch_end(self, outputs):\n",
        "\n",
        "        total = sum([x['batch_size'] for x in outputs])\n",
        "        avg_loss = sum([x['loss']*x['batch_size'] for x in outputs])/total\n",
        "\n",
        "        print(f\"Epoch {self.current_epoch}:\\t Train loss: {avg_loss:.4f}\")\n",
        "        return {'avg_train_loss': avg_loss}\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "\n",
        "        x, y, offsets = batch\n",
        "        y_hat = self(batch)\n",
        "\n",
        "        # compute loss\n",
        "        loss = F.binary_cross_entropy_with_logits(y_hat, y)\n",
        "        \n",
        "        # compute acc\n",
        "        preds = torch.round(torch.sigmoid(y_hat))\n",
        "        correct = (preds == y).float().sum()\n",
        "        acc = correct/len(y)\n",
        "\n",
        "        return {\"loss\": loss, \n",
        "                \"acc\": acc, \n",
        "                \"batch_size\": len(y)}\n",
        "\n",
        "    def validation_epoch_end(self, outputs, mode=\"val\"):\n",
        "      \n",
        "        total = sum([x['batch_size'] for x in outputs])\n",
        "        avg_loss = sum([x['loss']*x['batch_size'] for x in outputs])/total\n",
        "        avg_acc = sum([x['acc']*x['batch_size'] for x in outputs])/total\n",
        "      \n",
        "        if mode=='val':\n",
        "            print(f\"Epoch {self.current_epoch}:\\t Validation acc: {avg_acc:.4f}\\t Validation loss: {avg_loss:.4f}\")\n",
        "        \n",
        "        return {\"epoch_val_loss\": avg_loss, \"epoch_val_acc\": avg_acc}\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "\n",
        "        return self.validation_step(batch, batch_idx)\n",
        "      \n",
        "\n",
        "    def test_epoch_end(self, outputs):\n",
        "\n",
        "        outputs = self.validation_epoch_end(outputs, mode=\"test\")\n",
        "        return {\"test_loss\": outputs['epoch_val_loss'], \n",
        "                \"test_acc\": outputs['epoch_val_acc']\n",
        "                }\n",
        "      "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOALKgeUuqrx",
        "outputId": "6bb92f70-f815-4dbe-a850-2d26924b7c95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# load the pre-trained embedding - this\n",
        "# may take a couple minutes at first execution.\n",
        "embed_mat = ds.embedding_matrix()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [06:30, 2.21MB/s]                           \n",
            "100%|█████████▉| 399668/400000 [00:35<00:00, 11085.67it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4ACLOnlQShJ",
        "outputId": "23b05776-3d53-4d41-b186-a9f11b0e6e7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 980
        }
      },
      "source": [
        "model = FastText(len(ds.encoding), embed_mat=embed_mat)\n",
        "\n",
        "\n",
        "early_stop_callback = EarlyStopping(\n",
        "   monitor='epoch_val_loss',\n",
        "   min_delta=0.0001,\n",
        "   patience=3,\n",
        "   verbose=False,\n",
        "   mode='min'\n",
        ")\n",
        "\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    filepath='./checkpoints/'+'{epoch}',\n",
        "    save_top_k=1,\n",
        "    verbose=False,\n",
        "    monitor='epoch_val_loss',\n",
        "    mode='min',\n",
        "    prefix=model.__class__.__name__+\"_\"\n",
        ")\n",
        "\n",
        "trainer = pl.Trainer(gpus=1, progress_bar_refresh_rate=0, max_epochs=30, \n",
        "                     num_sanity_val_steps=0, \n",
        "                     early_stop_callback=early_stop_callback,\n",
        "                     checkpoint_callback=checkpoint_callback)\n",
        "trainer.fit(model, ds)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py:37: UserWarning: Could not log computational graph since the `model.example_input_array` attribute is not set or `input_array` was not given\n",
            "  warnings.warn(*args, **kwargs)\n",
            "\n",
            "  | Name      | Type         | Params\n",
            "-------------------------------------------\n",
            "0 | embedding | EmbeddingBag | 4 M   \n",
            "1 | fc        | Sequential   | 77 K  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0:\t Validation acc: 0.7580\t Validation loss: 0.4897\n",
            "Epoch 0:\t Train loss: 0.4815\n",
            "Epoch 1:\t Validation acc: 0.7638\t Validation loss: 0.4723\n",
            "Epoch 1:\t Train loss: 0.3753\n",
            "Epoch 2:\t Validation acc: 0.7695\t Validation loss: 0.4649\n",
            "Epoch 2:\t Train loss: 0.3624\n",
            "Epoch 3:\t Validation acc: 0.7672\t Validation loss: 0.4607\n",
            "Epoch 3:\t Train loss: 0.3569\n",
            "Epoch 4:\t Validation acc: 0.7706\t Validation loss: 0.4590\n",
            "Epoch 4:\t Train loss: 0.3523\n",
            "Epoch 5:\t Validation acc: 0.7672\t Validation loss: 0.4585\n",
            "Epoch 5:\t Train loss: 0.3480\n",
            "Epoch 6:\t Validation acc: 0.7661\t Validation loss: 0.4564\n",
            "Epoch 6:\t Train loss: 0.3441\n",
            "Epoch 7:\t Validation acc: 0.7683\t Validation loss: 0.4558\n",
            "Epoch 7:\t Train loss: 0.3401\n",
            "Epoch 8:\t Validation acc: 0.7695\t Validation loss: 0.4536\n",
            "Epoch 8:\t Train loss: 0.3368\n",
            "Epoch 9:\t Validation acc: 0.7729\t Validation loss: 0.4524\n",
            "Epoch 9:\t Train loss: 0.3336\n",
            "Epoch 10:\t Validation acc: 0.7683\t Validation loss: 0.4518\n",
            "Epoch 10:\t Train loss: 0.3305\n",
            "Epoch 11:\t Validation acc: 0.7787\t Validation loss: 0.4500\n",
            "Epoch 11:\t Train loss: 0.3274\n",
            "Epoch 12:\t Validation acc: 0.7764\t Validation loss: 0.4511\n",
            "Epoch 12:\t Train loss: 0.3242\n",
            "Epoch 13:\t Validation acc: 0.7764\t Validation loss: 0.4483\n",
            "Epoch 13:\t Train loss: 0.3221\n",
            "Epoch 14:\t Validation acc: 0.7752\t Validation loss: 0.4498\n",
            "Epoch 14:\t Train loss: 0.3185\n",
            "Epoch 15:\t Validation acc: 0.7844\t Validation loss: 0.4480\n",
            "Epoch 15:\t Train loss: 0.3165\n",
            "Epoch 16:\t Validation acc: 0.7844\t Validation loss: 0.4486\n",
            "Epoch 16:\t Train loss: 0.3139\n",
            "Epoch 17:\t Validation acc: 0.7775\t Validation loss: 0.4450\n",
            "Epoch 17:\t Train loss: 0.3105\n",
            "Epoch 18:\t Validation acc: 0.7856\t Validation loss: 0.4440\n",
            "Epoch 18:\t Train loss: 0.3089\n",
            "Epoch 19:\t Validation acc: 0.7844\t Validation loss: 0.4417\n",
            "Epoch 19:\t Train loss: 0.3062\n",
            "Epoch 20:\t Validation acc: 0.7833\t Validation loss: 0.4442\n",
            "Epoch 20:\t Train loss: 0.3045\n",
            "Epoch 21:\t Validation acc: 0.7856\t Validation loss: 0.4438\n",
            "Epoch 21:\t Train loss: 0.3012\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Saving latest checkpoint..\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 22:\t Validation acc: 0.7867\t Validation loss: 0.4419\n",
            "Epoch 22:\t Train loss: 0.2989\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfYv7tahQTJO",
        "outputId": "740138e7-4483-4c2f-a403-b0e842935f2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "test_results = trainer.test(model, \n",
        "                           ds.test_dataloader(), \n",
        "                           ckpt_path=checkpoint_callback.best_model_path)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "DATALOADER:0 TEST RESULTS\n",
            "{'test_acc': tensor(0.8023, device='cuda:0'),\n",
            " 'test_loss': tensor(0.4259, device='cuda:0')}\n",
            "--------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py:37: UserWarning: Could not log computational graph since the `model.example_input_array` attribute is not set or `input_array` was not given\n",
            "  warnings.warn(*args, **kwargs)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEO3rkANztG2"
      },
      "source": [
        "## 2. LSTM\n",
        "\n",
        "The appeal of the `FastText` model is its simplicity, however, it suffers from some inherent disadvantages. In particular, the model does not consider word order. The [paper](https://www.aclweb.org/anthology/E17-2068/) addresses this issue by including additional n-gram features to capture local word ordering. An alternative approach is to use a different model architecture designed for sequential data, recurrent neural networks. We now implement a single-layer LSTM for the sentiment classification task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81VY4WvQz1VJ"
      },
      "source": [
        "### Pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0C6zGr6zvRn"
      },
      "source": [
        "class SSTDataModuleLSTM(SSTDataModuleBase):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    @staticmethod\n",
        "    def _collate_fn(batch):\n",
        "        # get inputs and targets\n",
        "        data = [item[0] for item in batch]\n",
        "        targets = [item[1] for item in batch]\n",
        "\n",
        "        # to be able to pack sequences later on, need\n",
        "        # the original sequence lengths\n",
        "        seqlengths = [len(el) for el in data]\n",
        "    \n",
        "        # pad the sequences\n",
        "        x = pad_sequence(data, batch_first=True)\n",
        "\n",
        "        return (x, torch.Tensor(targets).float(), \n",
        "                      seqlengths)\n",
        "        \n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(self.sst_train, batch_size=64, \n",
        "                              collate_fn=self._collate_fn, shuffle=True)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(self.sst_val, batch_size=64, \n",
        "                              collate_fn=self._collate_fn)\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return DataLoader(self.sst_test, batch_size=64,\n",
        "                              collate_fn=self._collate_fn)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7LEuRqHPuy8"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tO6bwrWOPvee"
      },
      "source": [
        "class SentimentLSTM(pl.LightningModule):\n",
        "\n",
        "    def __init__(self, input_size, embed_mat):\n",
        "    \n",
        "        super().__init__()    \n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, 300, padding_idx=0)\n",
        "        if embed_mat is not None:\n",
        "            self.embedding = self.embedding.from_pretrained(torch.from_numpy(embed_mat).float())\n",
        "        self.lstm = nn.LSTM(300, 256, num_layers = 1, batch_first = True)\n",
        "        self.linear1 = nn.Linear(256, 64)\n",
        "        self.linear2 = nn.Linear(64, 1)\n",
        "        self.dropout = nn.Dropout()\n",
        "\n",
        "    def forward(self, batch):\n",
        "\n",
        "        inputs, _, seqlengths = batch\n",
        "        # inputs: [BATCH_SIZE, LONGEST_SEQ]\n",
        "    \n",
        "        embeds = self.embedding(inputs.long())\n",
        "        # embeds: [BATCH_SIZE, LONGEST_SEQ, EMBED_DIM]\n",
        "\n",
        "        embeds = self.dropout(embeds)\n",
        "\n",
        "        inputs = pack_padded_sequence(embeds, seqlengths, \n",
        "              enforce_sorted=False, batch_first=True)\n",
        "        # inputs: [SUM(SEQ_LENGTHS), EMBED_DIM)\n",
        "\n",
        "        packed_output, (hidden, cell) = self.lstm(inputs)\n",
        "        # packed_outputs: [SUM(SEQ_LENGTHS), LSTM_OUT]\n",
        "        # hidden: [1, BATCH_SIZE, LSTM_OUT]\n",
        "\n",
        "        lastState = hidden[-1]\n",
        "        # lastState: [BATCH_SIZE, LSTM_OUT]\n",
        "\n",
        "        output = self.dropout(F.relu(self.linear1(lastState)))\n",
        "        output = self.linear2(output).squeeze()\n",
        "\n",
        "        return output\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-4, \n",
        "                                     weight_decay=1e-05)\n",
        "        return optimizer\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "\n",
        "        x, y , seqlengths = batch\n",
        "        y_hat = self(batch)\n",
        "\n",
        "        # compute loss\n",
        "        loss = F.binary_cross_entropy_with_logits(y_hat, y)\n",
        "\n",
        "        return {'loss': loss, \n",
        "                \"batch_size\": len(y)}\n",
        "\n",
        "    def training_epoch_end(self, outputs):\n",
        "\n",
        "        total = sum([x['batch_size'] for x in outputs])\n",
        "        avg_loss = sum([x['loss']*x['batch_size'] for x in outputs])/total\n",
        "\n",
        "        print(f\"Epoch {self.current_epoch}:\\t Train loss: {avg_loss:.4f}\")\n",
        "        return {'avg_train_loss': avg_loss}\n",
        "\n",
        "    \n",
        "    def validation_step(self, batch, batch_idx):\n",
        "\n",
        "        x, y, offsets = batch\n",
        "        y_hat = self(batch)\n",
        "\n",
        "        # compute loss\n",
        "        loss = F.binary_cross_entropy_with_logits(y_hat, y)\n",
        "        \n",
        "        # compute acc\n",
        "        preds = torch.round(torch.sigmoid(y_hat))\n",
        "        correct = (preds == y).float().sum()\n",
        "        acc = correct/len(y)\n",
        "\n",
        "        return {\"loss\": loss, \n",
        "                \"acc\": acc, \n",
        "                \"batch_size\": len(y)}\n",
        "\n",
        "    def validation_epoch_end(self, outputs, mode=\"val\"):\n",
        "      \n",
        "        total = sum([x['batch_size'] for x in outputs])\n",
        "        avg_loss = sum([x['loss']*x['batch_size'] for x in outputs])/total\n",
        "        avg_acc = sum([x['acc']*x['batch_size'] for x in outputs])/total\n",
        "\n",
        "        if mode=='val':\n",
        "            print(f\"Epoch {self.current_epoch}:\\t Validation acc: {avg_acc:.4f}\\t Validation loss: {avg_loss:.4f}\")\n",
        "\n",
        "        return {\"epoch_val_loss\": avg_loss, \"epoch_val_acc\": avg_acc}\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "\n",
        "        return self.validation_step(batch, batch_idx)\n",
        "      \n",
        "    def test_epoch_end(self, outputs):\n",
        "\n",
        "        outputs = self.validation_epoch_end(outputs, mode=\"test\")\n",
        "        return {\"test_loss\": outputs['epoch_val_loss'], \n",
        "                \"test_acc\": outputs['epoch_val_acc']}"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YesMTW3RR5wo"
      },
      "source": [
        "ds = SSTDataModuleLSTM()\n",
        "ds.setup(min_freq=3)\n",
        "embed_mat = ds.embedding_matrix()"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dqly0of7QqGd",
        "outputId": "5d4471a9-283a-47b6-c00a-3dae6076df52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 703
        }
      },
      "source": [
        "model = SentimentLSTM(len(ds.encoding), embed_mat=embed_mat)\n",
        "\n",
        "early_stop_callback = EarlyStopping(\n",
        "   monitor='epoch_val_loss',\n",
        "   min_delta=0.0001,\n",
        "   patience=5,\n",
        "   verbose=False,\n",
        "   mode='min'\n",
        ")\n",
        "\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    filepath='./checkpoints/'+'{epoch}',\n",
        "    save_top_k=1,\n",
        "    verbose=False,\n",
        "    monitor='epoch_val_loss',\n",
        "    mode='min',\n",
        "    prefix=model.__class__.__name__+\"_\"\n",
        ")\n",
        "\n",
        "\n",
        "trainer = pl.Trainer(gpus=1, progress_bar_refresh_rate=0, max_epochs=30, \n",
        "                     num_sanity_val_steps=0, \n",
        "                     early_stop_callback=early_stop_callback,\n",
        "                     checkpoint_callback=checkpoint_callback)\n",
        "trainer.fit(model, ds)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py:37: UserWarning: Could not log computational graph since the `model.example_input_array` attribute is not set or `input_array` was not given\n",
            "  warnings.warn(*args, **kwargs)\n",
            "\n",
            "  | Name      | Type      | Params\n",
            "----------------------------------------\n",
            "0 | embedding | Embedding | 4 M   \n",
            "1 | lstm      | LSTM      | 571 K \n",
            "2 | linear1   | Linear    | 16 K  \n",
            "3 | linear2   | Linear    | 65    \n",
            "4 | dropout   | Dropout   | 0     \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0:\t Validation acc: 0.7775\t Validation loss: 0.4544\n",
            "Epoch 0:\t Train loss: 0.4833\n",
            "Epoch 1:\t Validation acc: 0.7936\t Validation loss: 0.4476\n",
            "Epoch 1:\t Train loss: 0.4026\n",
            "Epoch 2:\t Validation acc: 0.7878\t Validation loss: 0.4417\n",
            "Epoch 2:\t Train loss: 0.3812\n",
            "Epoch 3:\t Validation acc: 0.8085\t Validation loss: 0.4194\n",
            "Epoch 3:\t Train loss: 0.3599\n",
            "Epoch 4:\t Validation acc: 0.8108\t Validation loss: 0.4111\n",
            "Epoch 4:\t Train loss: 0.3443\n",
            "Epoch 5:\t Validation acc: 0.8142\t Validation loss: 0.4158\n",
            "Epoch 5:\t Train loss: 0.3315\n",
            "Epoch 6:\t Validation acc: 0.7947\t Validation loss: 0.4708\n",
            "Epoch 6:\t Train loss: 0.3194\n",
            "Epoch 7:\t Validation acc: 0.8280\t Validation loss: 0.3892\n",
            "Epoch 7:\t Train loss: 0.3087\n",
            "Epoch 8:\t Validation acc: 0.8280\t Validation loss: 0.3967\n",
            "Epoch 8:\t Train loss: 0.2982\n",
            "Epoch 9:\t Validation acc: 0.8177\t Validation loss: 0.3964\n",
            "Epoch 9:\t Train loss: 0.2886\n",
            "Epoch 10:\t Validation acc: 0.8314\t Validation loss: 0.4092\n",
            "Epoch 10:\t Train loss: 0.2783\n",
            "Epoch 11:\t Validation acc: 0.8257\t Validation loss: 0.3946\n",
            "Epoch 11:\t Train loss: 0.2741\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Saving latest checkpoint..\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 12:\t Validation acc: 0.8154\t Validation loss: 0.4435\n",
            "Epoch 12:\t Train loss: 0.2646\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGj6lcacRAB9",
        "outputId": "eeb7cfc7-354c-4bd2-b524-50382219da80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "test_results = trainer.test(model, \n",
        "                            ds.test_dataloader(), \n",
        "                            ckpt_path=checkpoint_callback.best_model_path)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "DATALOADER:0 TEST RESULTS\n",
            "{'test_acc': tensor(0.8325, device='cuda:0'),\n",
            " 'test_loss': tensor(0.3854, device='cuda:0')}\n",
            "--------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py:37: UserWarning: Could not log computational graph since the `model.example_input_array` attribute is not set or `input_array` was not given\n",
            "  warnings.warn(*args, **kwargs)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0sWlXlHWS6i"
      },
      "source": [
        "## Attention-LSTM\n",
        "\n",
        "In the LSTM-model presented above, the dense layer receives the last hidden state as input. This implies that all the information required to make a prediction must be contained in the last hidden state, thus creating a bottleneck of information.\n",
        "\n",
        "Rather than using the last hidden state as input, we can compute a representation through the use of weighted sum of all the hidden states by using an attention mechanism. In that way, we can \"focus\" on words that heavily influence the sentiment of the sentence.\n",
        "\n",
        "The model implemented is the word-sequence and word-attention model presented in [Hierarchical Attention Networks for Document Classification](https://www.aclweb.org/anthology/N16-1174/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYeRW9dfW1D2"
      },
      "source": [
        "class Attention(nn.Module):\n",
        "\n",
        "    def __init__(self, hidden_size, att_dim):\n",
        "        super().__init__()\n",
        "        self.w = nn.Linear(2*hidden_size, att_dim)\n",
        "        self.u_w = nn.Linear(att_dim, 1)\n",
        "\n",
        "    def forward(self, outputs, mask):\n",
        "\n",
        "        outputs = outputs.permute(0,2,1)\n",
        "        # outputs: [BATCH_SIZE, LSTM_OUT, LONGEST_SEQ]\n",
        "\n",
        "        # compute u_{it} representations of each of the hidden \n",
        "        u_it = torch.einsum('ki,bij->bkj', self.w.weight, outputs)\n",
        "        # u_it: [BATCH_SIZE, ATTN_OUT, LONGEST_SEQ]\n",
        "        \n",
        "        \n",
        "        # compute alpha\n",
        "        alpha = torch.einsum('ij, bjk->bk', self.u_w.weight, u_it)\n",
        "        # alpha: [BATCH_SIZE, LONGEST_SEQ]\n",
        "\n",
        "        # use mask\n",
        "        alpha = alpha.masked_fill(mask == 0, -1e-10)\n",
        "\n",
        "        return F.softmax(alpha, dim=1)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihhMGn-2WVON"
      },
      "source": [
        "class AttentionLSTM(pl.LightningModule):\n",
        "\n",
        "    def __init__(self, input_size, embed_mat):\n",
        "    \n",
        "        super().__init__()    \n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, 300, padding_idx=0)\n",
        "        if embed_mat is not None:\n",
        "            self.embedding = self.embedding.from_pretrained(torch.from_numpy(embed_mat).float())\n",
        "        self.attention = Attention(256, 200)\n",
        "        self.lstm = nn.LSTM(300, 256, bidirectional=True, batch_first = True)\n",
        "        self.fc1 = nn.Linear(256*2, 64)\n",
        "        self.fc2 = nn.Linear(64, 1)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.embed_dropout = nn.Dropout(0.1)\n",
        "\n",
        "    def _create_mask(self, inputs):\n",
        "        mask = (inputs != 0)\n",
        "        return mask \n",
        "\n",
        "    def forward(self, batch):\n",
        "\n",
        "        inputs, _, seqlengths = batch\n",
        "        # inputs: [BATCH_SIZE, LONGEST_SEQ]\n",
        "\n",
        "        mask = self._create_mask(inputs)\n",
        "        # mask: [BATCH_SIZE, 1, LONGEST_SEQ]\n",
        "\n",
        "        embeds = self.embedding(inputs.long())\n",
        "        # embeds: [BATCH_SIZE, LONGEST_SEQ, EMBED_DIM]\n",
        "\n",
        "        embeds = self.embed_dropout(embeds)\n",
        "\n",
        "        inputs = pack_padded_sequence(embeds, seqlengths, \n",
        "              enforce_sorted=False, batch_first=True)\n",
        "        # inputs: [SUM(SEQ_LENGTHS), EMBED_DIM)\n",
        "     \n",
        "        packed_outputs, (hidden, cell) = self.lstm(inputs)\n",
        "        # packed_outputs: [SUM(SEQ_LENGTHS), N_DIR * LSTM_OUT]\n",
        "        # hidden: [N_DIR * N_LAYERS, BATCH_SIZE, LSTM_OUT]\n",
        "\n",
        "        outputs, _ = pad_packed_sequence(packed_outputs, batch_first=True)\n",
        "        # outputs: [BATCH_SIZE, LONGEST_SEQ, N_DIR * LSTM_OUT]\n",
        "\n",
        "        a = self.attention(outputs, mask)\n",
        "        # a: [BATCH_SIZE, LONGEST_SEQ]\n",
        "\n",
        "        context = torch.einsum('bj, bjk -> bk', a, outputs)\n",
        "        # context: [BATCH_SIZE, N_DIR * LSTM_OUT]\n",
        "        \n",
        "        # linear layer\n",
        "        output = self.dropout(F.relu(self.fc1(context)))\n",
        "        output = self.fc2(output)\n",
        "\n",
        "        return output.squeeze()\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=0.0001, \n",
        "                                     weight_decay=1e-05)\n",
        "        return optimizer\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "\n",
        "        x, y , seqlengths = batch\n",
        "        y_hat = self(batch)\n",
        "\n",
        "        # compute loss\n",
        "        loss = F.binary_cross_entropy_with_logits(y_hat, y)\n",
        "\n",
        "        return {'loss': loss, \n",
        "                \"batch_size\": len(y)}\n",
        "\n",
        "    def training_epoch_end(self, outputs):\n",
        "\n",
        "        total = sum([x['batch_size'] for x in outputs])\n",
        "        avg_loss = sum([x['loss']*x['batch_size'] for x in outputs])/total\n",
        "\n",
        "        print(f\"Epoch {self.current_epoch}:\\t Train loss: {avg_loss:.4f}\")\n",
        "        return {'avg_train_loss': avg_loss}\n",
        "\n",
        "    \n",
        "    def validation_step(self, batch, batch_idx):\n",
        "\n",
        "        x, y, offsets = batch\n",
        "        y_hat = self(batch)\n",
        "\n",
        "        # compute loss\n",
        "        loss = F.binary_cross_entropy_with_logits(y_hat, y)\n",
        "        \n",
        "        # compute acc\n",
        "        preds = torch.round(torch.sigmoid(y_hat))\n",
        "        correct = (preds == y).float().sum()\n",
        "        acc = correct/len(y)\n",
        "\n",
        "        return {\"loss\": loss, \n",
        "                \"acc\": acc, \n",
        "                \"batch_size\": len(y)}\n",
        "\n",
        "    def validation_epoch_end(self, outputs, mode=\"val\"):\n",
        "      \n",
        "        total = sum([x['batch_size'] for x in outputs])\n",
        "        avg_loss = sum([x['loss']*x['batch_size'] for x in outputs])/total\n",
        "        avg_acc = sum([x['acc']*x['batch_size'] for x in outputs])/total\n",
        "      \n",
        "        if mode=='val':\n",
        "            print(f\"Epoch {self.current_epoch}:\\t Validation acc: {avg_acc:.4f}\\t Validation loss: {avg_loss:.4f}\")\n",
        "\n",
        "        return {\"epoch_val_loss\": avg_loss, \"epoch_val_acc\": avg_acc}\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "\n",
        "        return self.validation_step(batch, batch_idx)\n",
        "      \n",
        "\n",
        "    def test_epoch_end(self, outputs):\n",
        "\n",
        "        outputs = self.validation_epoch_end(outputs, mode=\"test\")\n",
        "        return {\"test_loss\": outputs['epoch_val_loss'], \n",
        "                \"test_acc\": outputs['epoch_val_acc']\n",
        "                }\n",
        "    "
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDYF_6BsXFjG",
        "outputId": "ab50bd24-5bd4-4b8d-cb7a-262f2098d0b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 801
        }
      },
      "source": [
        "model = AttentionLSTM(len(ds.encoding), embed_mat=embed_mat)\n",
        "\n",
        "early_stop_callback = EarlyStopping(\n",
        "   monitor='epoch_val_loss',\n",
        "   min_delta=0.0001,\n",
        "   patience=10,\n",
        "   verbose=False,\n",
        "   mode='min'\n",
        ")\n",
        "\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    filepath='./checkpoints/'+'{epoch}',\n",
        "    save_top_k=1,\n",
        "    verbose=False,\n",
        "    monitor='epoch_val_loss',\n",
        "    mode='min',\n",
        "    prefix=model.__class__.__name__+\"_\"\n",
        ")\n",
        "\n",
        "\n",
        "trainer = pl.Trainer(gpus=1, progress_bar_refresh_rate=0, max_epochs=50, \n",
        "                     num_sanity_val_steps=0, \n",
        "                     early_stop_callback=early_stop_callback,\n",
        "                     checkpoint_callback=checkpoint_callback)\n",
        "trainer.fit(model, ds)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py:37: UserWarning: Could not log computational graph since the `model.example_input_array` attribute is not set or `input_array` was not given\n",
            "  warnings.warn(*args, **kwargs)\n",
            "\n",
            "  | Name          | Type      | Params\n",
            "--------------------------------------------\n",
            "0 | embedding     | Embedding | 4 M   \n",
            "1 | attention     | Attention | 102 K \n",
            "2 | lstm          | LSTM      | 1 M   \n",
            "3 | fc1           | Linear    | 32 K  \n",
            "4 | fc2           | Linear    | 65    \n",
            "5 | dropout       | Dropout   | 0     \n",
            "6 | embed_dropout | Dropout   | 0     \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0:\t Validation acc: 0.7821\t Validation loss: 0.4538\n",
            "Epoch 0:\t Train loss: 0.4089\n",
            "Epoch 1:\t Validation acc: 0.8073\t Validation loss: 0.4214\n",
            "Epoch 1:\t Train loss: 0.3346\n",
            "Epoch 2:\t Validation acc: 0.8177\t Validation loss: 0.4063\n",
            "Epoch 2:\t Train loss: 0.3058\n",
            "Epoch 3:\t Validation acc: 0.8211\t Validation loss: 0.3970\n",
            "Epoch 3:\t Train loss: 0.2824\n",
            "Epoch 4:\t Validation acc: 0.8360\t Validation loss: 0.3754\n",
            "Epoch 4:\t Train loss: 0.2646\n",
            "Epoch 5:\t Validation acc: 0.8314\t Validation loss: 0.3844\n",
            "Epoch 5:\t Train loss: 0.2460\n",
            "Epoch 6:\t Validation acc: 0.8303\t Validation loss: 0.4043\n",
            "Epoch 6:\t Train loss: 0.2318\n",
            "Epoch 7:\t Validation acc: 0.8245\t Validation loss: 0.4055\n",
            "Epoch 7:\t Train loss: 0.2161\n",
            "Epoch 8:\t Validation acc: 0.8394\t Validation loss: 0.3940\n",
            "Epoch 8:\t Train loss: 0.2046\n",
            "Epoch 9:\t Validation acc: 0.8268\t Validation loss: 0.4221\n",
            "Epoch 9:\t Train loss: 0.1912\n",
            "Epoch 10:\t Validation acc: 0.8383\t Validation loss: 0.4076\n",
            "Epoch 10:\t Train loss: 0.1794\n",
            "Epoch 11:\t Validation acc: 0.8463\t Validation loss: 0.3893\n",
            "Epoch 11:\t Train loss: 0.1702\n",
            "Epoch 12:\t Validation acc: 0.8360\t Validation loss: 0.4071\n",
            "Epoch 12:\t Train loss: 0.1601\n",
            "Epoch 13:\t Validation acc: 0.8326\t Validation loss: 0.4460\n",
            "Epoch 13:\t Train loss: 0.1533\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Saving latest checkpoint..\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 14:\t Validation acc: 0.8337\t Validation loss: 0.4407\n",
            "Epoch 14:\t Train loss: 0.1438\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5Lu_NPVXdMu",
        "outputId": "70c5e5eb-2ea2-4586-bf39-99b4d01f7a37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "test_results = trainer.test(model, \n",
        "                            ds.test_dataloader(), \n",
        "                            ckpt_path=checkpoint_callback.best_model_path)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "DATALOADER:0 TEST RESULTS\n",
            "{'test_acc': tensor(0.8413, device='cuda:0'),\n",
            " 'test_loss': tensor(0.4147, device='cuda:0')}\n",
            "--------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py:37: UserWarning: Could not log computational graph since the `model.example_input_array` attribute is not set or `input_array` was not given\n",
            "  warnings.warn(*args, **kwargs)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQnMIcyqT8p0"
      },
      "source": [
        "## CNN\n",
        "\n",
        "We can use a CNN for text classification as presented in [Convolutional Neural Networks for Sentence Classification](https://www.aclweb.org/anthology/D14-1181/), by using convolution operations on the embeddings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jARq9K6rW11B"
      },
      "source": [
        "### Pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hu-uFOqdUI3r"
      },
      "source": [
        "class SSTDataModuleCNN(SSTDataModuleBase):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    @staticmethod\n",
        "    def _collate_fn(batch):\n",
        "        # get inputs and targets\n",
        "        data = [item[0] for item in batch]\n",
        "        targets = [item[1] for item in batch]\n",
        "    \n",
        "        # pad the sequences\n",
        "        x = pad_sequence(data, batch_first=True)\n",
        "\n",
        "        return x, torch.Tensor(targets).float()\n",
        "        \n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(self.sst_train, batch_size=64, \n",
        "                              collate_fn=self._collate_fn, shuffle=True)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(self.sst_val, batch_size=64, \n",
        "                              collate_fn=self._collate_fn)\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return DataLoader(self.sst_test, batch_size=64,\n",
        "                              collate_fn=self._collate_fn)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umA4rsPNW32i"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWQ0f4oXUUKn"
      },
      "source": [
        "# TODO: rename variables\n",
        "class TextCNN(pl.LightningModule):\n",
        "    \n",
        "    def __init__(self, input_size, embed_mat=None):\n",
        "        \n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(input_size, 300, padding_idx=0)\n",
        "        if embed_mat is not None:\n",
        "            self.embedding = self.embedding.from_pretrained(torch.from_numpy(embed_mat).float())\n",
        "\n",
        "        self.convs = nn.ModuleList([\n",
        "                                    nn.Conv1d(in_channels = 300, \n",
        "                                              out_channels = 100, \n",
        "                                              kernel_size = fs)\n",
        "                                    for fs in [3,4,5]\n",
        "                                    ])\n",
        "        \n",
        "        self.fc = nn.Linear(3 * 100, 1)\n",
        "        \n",
        "        self.dropout = nn.Dropout()\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=0.0001, \n",
        "                                     weight_decay=1e-05)\n",
        "        return optimizer\n",
        "\n",
        "    def forward(self, batch):\n",
        "\n",
        "        inputs, _ = batch\n",
        "        # inputs:  [BATCH_SIZE, LONGEST_SEQ]\n",
        "        \n",
        "        embeds = self.embedding(inputs).permute(0,2,1)\n",
        "        # embeds = [BATCH_SIZE, EMBED_DIM, LONGEST_SEQ]\n",
        "        \n",
        "        convs = [F.relu(conv(embeds)) for conv in self.convs]\n",
        "        # convs: List[[BATCH_SIZE, CONV_OUT_DIM, LONGEST_SEQ - KERNEL_SIZE + 1]]  \n",
        "        \n",
        "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in convs]\n",
        "        # pooled: List[[BATCH_SIZE, CONV_OUT_DIM]]\n",
        "        \n",
        "        conv_out = self.dropout(torch.cat(pooled, dim = 1))\n",
        "        # conv_out: [BATCH_SIZE, N_FILTERS * CONV_OUT_DIM]\n",
        "            \n",
        "        return self.fc(conv_out).squeeze()\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "\n",
        "        x, y = batch\n",
        "        y_hat = self(batch)\n",
        "\n",
        "        # compute loss\n",
        "        loss = F.binary_cross_entropy_with_logits(y_hat, y)\n",
        "\n",
        "        return {'loss': loss, \n",
        "                \"batch_size\": len(y)}\n",
        "\n",
        "    def training_epoch_end(self, outputs):\n",
        "\n",
        "        total = sum([x['batch_size'] for x in outputs])\n",
        "        avg_loss = sum([x['loss']*x['batch_size'] for x in outputs])/total\n",
        "\n",
        "        print(f\"Epoch {self.current_epoch}:\\t Train loss: {avg_loss:.4f}\")\n",
        "        return {'avg_train_loss': avg_loss}\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "\n",
        "        x, y = batch\n",
        "        y_hat = self(batch)\n",
        "\n",
        "        # compute loss\n",
        "        loss = F.binary_cross_entropy_with_logits(y_hat, y)\n",
        "        \n",
        "        # compute acc\n",
        "        preds = torch.round(torch.sigmoid(y_hat))\n",
        "        correct = (preds == y).float().sum()\n",
        "        acc = correct/len(y)\n",
        "\n",
        "        return {\"loss\": loss, \n",
        "                \"acc\": acc, \n",
        "                \"batch_size\": len(y)}\n",
        "\n",
        "    def validation_epoch_end(self, outputs, mode=\"val\"):\n",
        "      \n",
        "        total = sum([x['batch_size'] for x in outputs])\n",
        "        avg_loss = sum([x['loss']*x['batch_size'] for x in outputs])/total\n",
        "        avg_acc = sum([x['acc']*x['batch_size'] for x in outputs])/total\n",
        "      \n",
        "        if mode=='val':\n",
        "            print(f\"Epoch {self.current_epoch}:\\t Validation acc: {avg_acc:.4f}\\t Validation loss: {avg_loss:.4f}\")\n",
        "        \n",
        "        return {\"epoch_val_loss\": avg_loss, \"epoch_val_acc\": avg_acc}\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "\n",
        "        return self.validation_step(batch, batch_idx)\n",
        "      \n",
        "\n",
        "    def test_epoch_end(self, outputs):\n",
        "\n",
        "        outputs = self.validation_epoch_end(outputs, mode=\"test\")\n",
        "        return {\"test_loss\": outputs['epoch_val_loss'], \n",
        "                \"test_acc\": outputs['epoch_val_acc']\n",
        "                }"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pArmGjHYU6la"
      },
      "source": [
        "ds = SSTDataModuleCNN()\n",
        "ds.setup(min_freq=3)\n",
        "embed_mat = ds.embedding_matrix()"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6MBEU75VA3n",
        "outputId": "1a1d1a6e-8613-4b90-ee87-e06930a7f603",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 785
        }
      },
      "source": [
        "model = TextCNN(len(ds.encoding), embed_mat=embed_mat)\n",
        "\n",
        "early_stop_callback = EarlyStopping(\n",
        "   monitor='epoch_val_loss',\n",
        "   min_delta=0.0001,\n",
        "   patience=5,\n",
        "   verbose=False,\n",
        "   mode='min'\n",
        ")\n",
        "\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    filepath='./checkpoints/'+'{epoch}',\n",
        "    save_top_k=1,\n",
        "    verbose=False,\n",
        "    monitor='epoch_val_loss',\n",
        "    mode='min',\n",
        "    prefix=model.__class__.__name__+\"_\"\n",
        ")\n",
        "\n",
        "\n",
        "trainer = pl.Trainer(gpus=1, progress_bar_refresh_rate=0, max_epochs=30, \n",
        "                     num_sanity_val_steps=0, \n",
        "                     early_stop_callback=early_stop_callback,\n",
        "                     checkpoint_callback=checkpoint_callback)\n",
        "trainer.fit(model, ds)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py:37: UserWarning: Could not log computational graph since the `model.example_input_array` attribute is not set or `input_array` was not given\n",
            "  warnings.warn(*args, **kwargs)\n",
            "\n",
            "  | Name      | Type       | Params\n",
            "-----------------------------------------\n",
            "0 | embedding | Embedding  | 4 M   \n",
            "1 | convs     | ModuleList | 360 K \n",
            "2 | fc        | Linear     | 301   \n",
            "3 | dropout   | Dropout    | 0     \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0:\t Validation acc: 0.7924\t Validation loss: 0.4427\n",
            "Epoch 0:\t Train loss: 0.4201\n",
            "Epoch 1:\t Validation acc: 0.8016\t Validation loss: 0.4236\n",
            "Epoch 1:\t Train loss: 0.3209\n",
            "Epoch 2:\t Validation acc: 0.7947\t Validation loss: 0.4177\n",
            "Epoch 2:\t Train loss: 0.2948\n",
            "Epoch 3:\t Validation acc: 0.7993\t Validation loss: 0.4236\n",
            "Epoch 3:\t Train loss: 0.2759\n",
            "Epoch 4:\t Validation acc: 0.8016\t Validation loss: 0.4195\n",
            "Epoch 4:\t Train loss: 0.2592\n",
            "Epoch 5:\t Validation acc: 0.8028\t Validation loss: 0.4072\n",
            "Epoch 5:\t Train loss: 0.2422\n",
            "Epoch 6:\t Validation acc: 0.8085\t Validation loss: 0.4087\n",
            "Epoch 6:\t Train loss: 0.2274\n",
            "Epoch 7:\t Validation acc: 0.8062\t Validation loss: 0.4110\n",
            "Epoch 7:\t Train loss: 0.2146\n",
            "Epoch 8:\t Validation acc: 0.8154\t Validation loss: 0.4069\n",
            "Epoch 8:\t Train loss: 0.2043\n",
            "Epoch 9:\t Validation acc: 0.8073\t Validation loss: 0.4110\n",
            "Epoch 9:\t Train loss: 0.1939\n",
            "Epoch 10:\t Validation acc: 0.8154\t Validation loss: 0.4044\n",
            "Epoch 10:\t Train loss: 0.1837\n",
            "Epoch 11:\t Validation acc: 0.8131\t Validation loss: 0.4163\n",
            "Epoch 11:\t Train loss: 0.1761\n",
            "Epoch 12:\t Validation acc: 0.8154\t Validation loss: 0.4231\n",
            "Epoch 12:\t Train loss: 0.1681\n",
            "Epoch 13:\t Validation acc: 0.8028\t Validation loss: 0.4255\n",
            "Epoch 13:\t Train loss: 0.1611\n",
            "Epoch 14:\t Validation acc: 0.8119\t Validation loss: 0.4206\n",
            "Epoch 14:\t Train loss: 0.1552\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Saving latest checkpoint..\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 15:\t Validation acc: 0.8177\t Validation loss: 0.4244\n",
            "Epoch 15:\t Train loss: 0.1490\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhGrdLggVEZ-",
        "outputId": "3c33db91-853d-49ba-d16c-909485b7ad25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "test_results = trainer.test(model, \n",
        "                            ds.test_dataloader(), \n",
        "                            ckpt_path=checkpoint_callback.best_model_path)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "DATALOADER:0 TEST RESULTS\n",
            "{'test_acc': tensor(0.8413, device='cuda:0'),\n",
            " 'test_loss': tensor(0.3777, device='cuda:0')}\n",
            "--------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py:37: UserWarning: Could not log computational graph since the `model.example_input_array` attribute is not set or `input_array` was not given\n",
            "  warnings.warn(*args, **kwargs)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcEMe0ARZrqr"
      },
      "source": [
        "## Recurrent Neural Filters\n",
        "\n",
        "We now present a variant of the CNN model which uses a recurrent network as a convolution filter. The embeddings are split into chunks, and an LSTM is applied to each chunk to compute a representation. The representations are then aggregated using a pooling operations. More details are in the paper, [Convolutional Neural Networks with Recurrent Neural Filters](https://www.aclweb.org/anthology/D18-1109/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kj_RUv10Zsnr"
      },
      "source": [
        "class TimeDistributedLSTM(pl.LightningModule):\n",
        "    def __init__(self, time_axis):        \n",
        "        super().__init__()\n",
        "\n",
        "        self.time_axis = time_axis\n",
        "        self.lstm = nn.LSTM(300, 300, batch_first = True)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        batch_size = x.shape[0]\n",
        "        time_steps = x.shape[self.time_axis]\n",
        "        embed_dim = x.shape[-1] \n",
        "        outputs = torch.zeros(x.shape[0], time_steps, embed_dim, device=self.device)\n",
        "        \n",
        "        for i in range(time_steps):\n",
        "            x_input = torch.index_select(x, dim=self.time_axis, index=torch.tensor([i], device=self.device).long()).squeeze()\n",
        "            \n",
        "            output_t, (cell_t, hidden_t) = self.lstm(x_input)\n",
        "            \n",
        "            outputs[:, i, :] = hidden_t\n",
        "           \n",
        "        return outputs"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1XpnBZzQ3X2"
      },
      "source": [
        "def format_conv_input(x, filter_width, sent_len):\n",
        "\n",
        "    chunks = []\n",
        "    for i in range(sent_len - filter_width + 1):\n",
        "        chunk = x[:, i:i+filter_width, :]\n",
        "        chunk = chunk.unsqueeze(1)\n",
        "        chunks.append(chunk)\n",
        "    return torch.cat(chunks, 1)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-r0ToV1h4ez"
      },
      "source": [
        "class RNF(pl.LightningModule):\n",
        "    \n",
        "    def __init__(self, input_size, embed_mat=None):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, 300, padding_idx=0)\n",
        "        if embed_mat is not None:\n",
        "            self.embedding = self.embedding.from_pretrained(torch.from_numpy(embed_mat).float())\n",
        "\n",
        "        self.filter_width = 5\n",
        "        self.time_lstm = TimeDistributedLSTM(time_axis=1)\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(300, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(256, 1),\n",
        "        )\n",
        "\n",
        "    def forward(self, batch):\n",
        "\n",
        "        inputs, _ = batch\n",
        "        # inputs: [BATCH_SIZE, LONGEST_SEQ]\n",
        "        \n",
        "        embedded = self.embedding(inputs)       \n",
        "        # embedded: [BATCH_SIZE, LONGEST_SEQ, EMBED_DIM]\n",
        "\n",
        "        lstm_inputs = format_conv_input(embedded, \n",
        "                                        filter_width=self.filter_width, \n",
        "                                        sent_len=embedded.shape[1])\n",
        "        # lstm_inputs: [BATCH SIZE, LONGEST SEQ - FILTER_WIDTH + 1, \n",
        "        # FILTER_WIDTH, EMBED_DIM]\n",
        "\n",
        "        lstm_outputs = self.time_lstm(lstm_inputs)\n",
        "        # lstm_outputs: [BATCH SIZE, LONGEST SEQ - FILTER_WIDTH + 1, \n",
        "        # FILTER_WIDTH, LSTM_OUT]\n",
        "\n",
        "        lstm_outputs = F.max_pool1d(lstm_outputs.permute(0,2,1), \n",
        "                                    kernel_size=lstm_outputs.shape[1]).squeeze()\n",
        "        # lstm_outputs: [BATCH SIZE, LSTM_OUT]\n",
        "        \n",
        "        outputs = self.fc(lstm_outputs)\n",
        "        return outputs.squeeze()\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=0.0001, \n",
        "                                     weight_decay=1e-05)\n",
        "        return optimizer\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "\n",
        "        x, y = batch\n",
        "        y_hat = self(batch)\n",
        "\n",
        "        # compute loss\n",
        "        loss = F.binary_cross_entropy_with_logits(y_hat, y)\n",
        "\n",
        "        return {'loss': loss, \n",
        "                \"batch_size\": len(y)}\n",
        "\n",
        "    def training_epoch_end(self, outputs):\n",
        "\n",
        "        total = sum([x['batch_size'] for x in outputs])\n",
        "        avg_loss = sum([x['loss']*x['batch_size'] for x in outputs])/total\n",
        "\n",
        "        print(f\"Epoch {self.current_epoch}:\\t Train loss: {avg_loss:.4f}\")\n",
        "        return {'avg_train_loss': avg_loss}\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "\n",
        "        x, y = batch\n",
        "        y_hat = self(batch)\n",
        "\n",
        "        # compute loss\n",
        "        loss = F.binary_cross_entropy_with_logits(y_hat, y)\n",
        "        \n",
        "        # compute acc\n",
        "        preds = torch.round(torch.sigmoid(y_hat))\n",
        "        correct = (preds == y).float().sum()\n",
        "        acc = correct/len(y)\n",
        "\n",
        "        return {\"loss\": loss, \n",
        "                \"acc\": acc, \n",
        "                \"batch_size\": len(y)}\n",
        "\n",
        "    def validation_epoch_end(self, outputs, mode=\"val\"):\n",
        "      \n",
        "        total = sum([x['batch_size'] for x in outputs])\n",
        "        avg_loss = sum([x['loss']*x['batch_size'] for x in outputs])/total\n",
        "        avg_acc = sum([x['acc']*x['batch_size'] for x in outputs])/total\n",
        "      \n",
        "        if mode=='val':\n",
        "            print(f\"Epoch {self.current_epoch}:\\t Validation acc: {avg_acc:.4f}\\t Validation loss: {avg_loss:.4f}\")\n",
        "        \n",
        "        return {\"epoch_val_loss\": avg_loss, \"epoch_val_acc\": avg_acc}\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "\n",
        "        return self.validation_step(batch, batch_idx)\n",
        "      \n",
        "\n",
        "    def test_epoch_end(self, outputs):\n",
        "\n",
        "        outputs = self.validation_epoch_end(outputs, mode=\"test\")\n",
        "        return {\"test_loss\": outputs['epoch_val_loss'], \n",
        "                \"test_acc\": outputs['epoch_val_acc']\n",
        "                }\n"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3_pfHOzUKK4"
      },
      "source": [
        "ds = SSTDataModuleCNN()\n",
        "ds.setup(min_freq=3)\n",
        "emlbed_mat = ds.embedding_matrix()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5k8g27BMSS1z",
        "outputId": "629a2bdf-208f-438f-a9b3-2162bb813c99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        }
      },
      "source": [
        "model = RNF(len(ds.encoding), embed_mat=embed_mat)\n",
        "\n",
        "early_stop_callback = EarlyStopping(\n",
        "   monitor='epoch_val_loss',\n",
        "   min_delta=0.0001,\n",
        "   patience=5,\n",
        "   verbose=False,\n",
        "   mode='min'\n",
        ")\n",
        "\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    filepath='./checkpoints/'+'{epoch}',\n",
        "    save_top_k=1,\n",
        "    verbose=False,\n",
        "    monitor='epoch_val_loss',\n",
        "    mode='min',\n",
        "    prefix=model.__class__.__name__+\"_\"\n",
        ")\n",
        "\n",
        "\n",
        "trainer = pl.Trainer(gpus=1, progress_bar_refresh_rate=0, max_epochs=30, \n",
        "                     num_sanity_val_steps=0, \n",
        "                     early_stop_callback=early_stop_callback,\n",
        "                     checkpoint_callback=checkpoint_callback)\n",
        "trainer.fit(model, ds)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py:37: UserWarning: Could not log computational graph since the `model.example_input_array` attribute is not set or `input_array` was not given\n",
            "  warnings.warn(*args, **kwargs)\n",
            "\n",
            "  | Name      | Type                | Params\n",
            "--------------------------------------------------\n",
            "0 | embedding | Embedding           | 4 M   \n",
            "1 | time_lstm | TimeDistributedLSTM | 722 K \n",
            "2 | fc        | Sequential          | 77 K  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0:\t Validation acc: 0.7810\t Validation loss: 0.4485\n",
            "Epoch 0:\t Train loss: 0.3957\n",
            "Epoch 1:\t Validation acc: 0.7936\t Validation loss: 0.4311\n",
            "Epoch 1:\t Train loss: 0.3145\n",
            "Epoch 2:\t Validation acc: 0.8062\t Validation loss: 0.4130\n",
            "Epoch 2:\t Train loss: 0.2826\n",
            "Epoch 3:\t Validation acc: 0.8119\t Validation loss: 0.4066\n",
            "Epoch 3:\t Train loss: 0.2540\n",
            "Epoch 4:\t Validation acc: 0.8165\t Validation loss: 0.4076\n",
            "Epoch 4:\t Train loss: 0.2246\n",
            "Epoch 5:\t Validation acc: 0.8177\t Validation loss: 0.4065\n",
            "Epoch 5:\t Train loss: 0.2000\n",
            "Epoch 6:\t Validation acc: 0.8131\t Validation loss: 0.4149\n",
            "Epoch 6:\t Train loss: 0.1779\n",
            "Epoch 7:\t Validation acc: 0.8096\t Validation loss: 0.4280\n",
            "Epoch 7:\t Train loss: 0.1599\n",
            "Epoch 8:\t Validation acc: 0.8222\t Validation loss: 0.4298\n",
            "Epoch 8:\t Train loss: 0.1438\n",
            "Epoch 9:\t Validation acc: 0.8096\t Validation loss: 0.4515\n",
            "Epoch 9:\t Train loss: 0.1298\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Saving latest checkpoint..\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 10:\t Validation acc: 0.8222\t Validation loss: 0.4782\n",
            "Epoch 10:\t Train loss: 0.1184\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDRCpEHBSdVl",
        "outputId": "edd0bc27-1624-4f18-fb26-c67f7492f160",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "test_results = trainer.test(model, \n",
        "                            ds.test_dataloader(), \n",
        "                            ckpt_path=checkpoint_callback.best_model_path)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py:37: UserWarning: Could not log computational graph since the `model.example_input_array` attribute is not set or `input_array` was not given\n",
            "  warnings.warn(*args, **kwargs)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "DATALOADER:0 TEST RESULTS\n",
            "{'test_acc': tensor(0.8298, device='cuda:0'),\n",
            " 'test_loss': tensor(0.4330, device='cuda:0')}\n",
            "--------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xV2DLPrSZfM5"
      },
      "source": [
        "## Neural Semantic Encoders"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhZn2g7UM8pf"
      },
      "source": [
        "The final model is an implemenations of [Neural Semantic Encoders](https://www.aclweb.org/anthology/E17-1038/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1kPCSmAz_Or"
      },
      "source": [
        "class NSE(pl.LightningModule):\n",
        "\n",
        "\n",
        "    def __init__(self, input_size, embed_mat=None):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, 300, padding_idx=0)\n",
        "        if embed_mat is not None:\n",
        "            self.embedding = self.embedding.from_pretrained(torch.from_numpy(embed_mat).float())\n",
        "\n",
        "        self.read_lstm = nn.LSTM(300, 300, batch_first = True)\n",
        "        self.write_lstm = nn.LSTM(2*300, 300, batch_first=True)\n",
        "        self.compose_layer = nn.Linear(2*300, 2*300)\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(300, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(256, 1),\n",
        "        )\n",
        "\n",
        "    def _init_hidden(self, batch_size, hidden_dim):\n",
        "        return (torch.zeros(1, batch_size, hidden_dim, device=self.device).requires_grad_(),\n",
        "                torch.zeros(1, batch_size, hidden_dim, device=self.device).requires_grad_())\n",
        "    \n",
        "    def _compose(self, o_t, m_t):\n",
        "\n",
        "        \"\"\"\n",
        "        Compose operation.\n",
        "        Eq. (4)\n",
        "        \"\"\"\n",
        "        c_t = self.compose_layer(torch.cat([o_t, m_t], dim=1))\n",
        "        # c_t: [BATCH_SIZE, 2*N_UNITS]\n",
        "        return c_t\n",
        "\n",
        "    def _read(self, M_t, x_t, hidden):\n",
        "\n",
        "        \"\"\"\n",
        "        Read operation.\n",
        "        Eq. (1)-(3)\n",
        "        \"\"\"\n",
        "        o_t, hidden = self.read_lstm(F.dropout(x_t, 0.3), hidden)\n",
        "        # o_t: [BATCH_SIZE, 1, DIM]\n",
        "\n",
        "        o_t = o_t.squeeze(1)\n",
        "        # o_t: [BATCH_SIZE, DIM]\n",
        "        \n",
        "        z_t = F.softmax(torch.einsum(\"bo,bko->bk\", o_t, M_t), dim=1)\n",
        "        m_rt = torch.einsum(\"bk,bko->bo\", z_t, M_t)\n",
        "        return o_t, m_rt, z_t, hidden\n",
        "\n",
        "    def _write(self, M_t, c_t, z_t, hidden):\n",
        "\n",
        "        batch_size = c_t.shape[0]\n",
        "        len = z_t.shape[1]\n",
        "        dim = M_t.shape[2]\n",
        "\n",
        "        h_t, hidden = self.write_lstm(F.dropout(c_t.unsqueeze(1), 0.3), hidden)\n",
        "        z_t_e_k = torch.einsum('ki,kj->kji', [torch.ones(batch_size, dim, device=self.device), z_t])\n",
        "        M_t = (1 - z_t_e_k) * M_t + torch.einsum('ki,kj->kij', \n",
        "            [torch.ones(batch_size,len, device=self.device), \n",
        "             h_t.squeeze(1)]) * z_t_e_k\n",
        "\n",
        "        return M_t, h_t, hidden\n",
        "\n",
        "    def forward(self, batch):\n",
        "        \n",
        "        inputs, _, seqlengths = batch\n",
        "        # inputs: [BATCH_SIZE, LONGEST_SEQ]\n",
        "\n",
        "        embeds = self.embedding(inputs.long())\n",
        "        # embeds: [BATCH_SIZE, LONGEST_SEQ, EMBED_DIM]\n",
        "\n",
        "        M_t = embeds\n",
        "\n",
        "        all_outputs = torch.zeros(inputs.shape[0], inputs.shape[1], \n",
        "                                  300, device=self.device)\n",
        "        idx = torch.tensor(seqlengths)\n",
        "        idx = idx - 1 \n",
        "        \n",
        "        read_hidden = self._init_hidden(inputs.shape[0], 300)\n",
        "        write_hidden = self._init_hidden(inputs.shape[0], 300)\n",
        "\n",
        "        for i in range(inputs.shape[1]):\n",
        "\n",
        "            x_t = torch.index_select(embeds, 1, torch.tensor([i]).long().cuda())\n",
        "            # x_t: [BATCH_SIZE, 1, DIM]\n",
        "\n",
        "            o_t, m_rt, z_t, read_hidden = self._read(M_t, x_t, read_hidden)\n",
        "\n",
        "            c_t = self._compose(o_t, m_rt)\n",
        "\n",
        "            M_t, h_t, write_hidden = self._write(M_t, c_t, z_t, write_hidden)\n",
        "\n",
        "            all_outputs[:, i, :] = h_t.squeeze(1)\n",
        "\n",
        "        output = all_outputs[torch.arange(all_outputs.size(0)), idx]\n",
        "        output = self.fc(output)\n",
        "\n",
        "        return output.squeeze()\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=0.0001, \n",
        "                                     weight_decay=1e-05)\n",
        "        return optimizer\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "\n",
        "        x, y , seqlengths = batch\n",
        "        y_hat = self(batch)\n",
        "\n",
        "        # compute loss\n",
        "        loss = F.binary_cross_entropy_with_logits(y_hat, y)\n",
        "\n",
        "        return {'loss': loss, \n",
        "                \"batch_size\": len(y)}\n",
        "\n",
        "    def training_epoch_end(self, outputs):\n",
        "\n",
        "        total = sum([x['batch_size'] for x in outputs])\n",
        "        avg_loss = sum([x['loss']*x['batch_size'] for x in outputs])/total\n",
        "\n",
        "        print(f\"Epoch {self.current_epoch}:\\t Train loss: {avg_loss:.4f}\")\n",
        "        return {'avg_train_loss': avg_loss}\n",
        "\n",
        "    \n",
        "    def validation_step(self, batch, batch_idx):\n",
        "\n",
        "        x, y, offsets = batch\n",
        "        y_hat = self(batch)\n",
        "\n",
        "        # compute loss\n",
        "        loss = F.binary_cross_entropy_with_logits(y_hat, y)\n",
        "        \n",
        "        # compute acc\n",
        "        preds = torch.round(torch.sigmoid(y_hat))\n",
        "        correct = (preds == y).float().sum()\n",
        "        acc = correct/len(y)\n",
        "\n",
        "        return {\"loss\": loss, \n",
        "                \"acc\": acc, \n",
        "                \"batch_size\": len(y)}\n",
        "\n",
        "    def validation_epoch_end(self, outputs, mode=\"val\"):\n",
        "      \n",
        "        total = sum([x['batch_size'] for x in outputs])\n",
        "        avg_loss = sum([x['loss']*x['batch_size'] for x in outputs])/total\n",
        "        avg_acc = sum([x['acc']*x['batch_size'] for x in outputs])/total\n",
        "      \n",
        "        if mode=='val':\n",
        "            print(f\"Epoch {self.current_epoch}:\\t Validation acc: {avg_acc:.4f}\\t Validation loss: {avg_loss:.4f}\")\n",
        "\n",
        "        return {\"epoch_val_loss\": avg_loss, \"epoch_val_acc\": avg_acc}\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "\n",
        "        return self.validation_step(batch, batch_idx)\n",
        "      \n",
        "\n",
        "    def test_epoch_end(self, outputs):\n",
        "\n",
        "        outputs = self.validation_epoch_end(outputs, mode=\"test\")\n",
        "        return {\"test_loss\": outputs['epoch_val_loss'], \n",
        "                \"test_acc\": outputs['epoch_val_acc']\n",
        "                }"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ao6nxS--YTUc"
      },
      "source": [
        "ds = SSTDataModuleLSTM()\n",
        "ds.setup(min_freq=3)\n",
        "embed_mat = ds.embedding_matrix()"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EdI046xvDEzi",
        "outputId": "399c36f0-8b1d-443c-9d2e-28dc71c4babc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        }
      },
      "source": [
        "model = NSE(len(ds.encoding), embed_mat=embed_mat)\n",
        "\n",
        "early_stop_callback = EarlyStopping(\n",
        "   monitor='epoch_val_loss',\n",
        "   min_delta=0.0001,\n",
        "   patience=3,\n",
        "   verbose=False,\n",
        "   mode='min'\n",
        ")\n",
        "\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    filepath='./checkpoints/'+'{epoch}',\n",
        "    save_top_k=1,\n",
        "    verbose=False,\n",
        "    monitor='epoch_val_loss',\n",
        "    mode='min',\n",
        "    prefix=model.__class__.__name__+\"_\"\n",
        ")\n",
        "\n",
        "\n",
        "trainer = pl.Trainer(gpus=1, progress_bar_refresh_rate=0, max_epochs=30, \n",
        "                     num_sanity_val_steps=0, \n",
        "                     early_stop_callback=early_stop_callback,\n",
        "                     checkpoint_callback=checkpoint_callback)\n",
        "trainer.fit(model, ds)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py:37: UserWarning: Could not log computational graph since the `model.example_input_array` attribute is not set or `input_array` was not given\n",
            "  warnings.warn(*args, **kwargs)\n",
            "\n",
            "  | Name          | Type       | Params\n",
            "---------------------------------------------\n",
            "0 | embedding     | Embedding  | 4 M   \n",
            "1 | read_lstm     | LSTM       | 722 K \n",
            "2 | write_lstm    | LSTM       | 1 M   \n",
            "3 | compose_layer | Linear     | 360 K \n",
            "4 | fc            | Sequential | 77 K  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0:\t Validation acc: 0.7775\t Validation loss: 0.4591\n",
            "Epoch 0:\t Train loss: 0.3850\n",
            "Epoch 1:\t Validation acc: 0.8050\t Validation loss: 0.4244\n",
            "Epoch 1:\t Train loss: 0.3064\n",
            "Epoch 2:\t Validation acc: 0.8016\t Validation loss: 0.4206\n",
            "Epoch 2:\t Train loss: 0.2825\n",
            "Epoch 3:\t Validation acc: 0.8096\t Validation loss: 0.4218\n",
            "Epoch 3:\t Train loss: 0.2643\n",
            "Epoch 4:\t Validation acc: 0.8234\t Validation loss: 0.3987\n",
            "Epoch 4:\t Train loss: 0.2494\n",
            "Epoch 5:\t Validation acc: 0.8131\t Validation loss: 0.4431\n",
            "Epoch 5:\t Train loss: 0.2330\n",
            "Epoch 6:\t Validation acc: 0.7833\t Validation loss: 0.4833\n",
            "Epoch 6:\t Train loss: 0.2181\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Saving latest checkpoint..\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 7:\t Validation acc: 0.8039\t Validation loss: 0.4322\n",
            "Epoch 7:\t Train loss: 0.2046\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMu7hrcWDNt9",
        "outputId": "af918848-3d56-4b8f-bc69-6a5e9330b7c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "test_results = trainer.test(model, \n",
        "                            ds.test_dataloader(), \n",
        "                            ckpt_path=checkpoint_callback.best_model_path)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py:37: UserWarning: Could not log computational graph since the `model.example_input_array` attribute is not set or `input_array` was not given\n",
            "  warnings.warn(*args, **kwargs)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "DATALOADER:0 TEST RESULTS\n",
            "{'test_acc': tensor(0.8292, device='cuda:0'),\n",
            " 'test_loss': tensor(0.3782, device='cuda:0')}\n",
            "--------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
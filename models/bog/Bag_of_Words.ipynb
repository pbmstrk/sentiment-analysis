{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Copy of Copy of Bag_of_Words.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mYbj7WHxZCWc"
      },
      "source": [
        "# Sentiment Analysis: Bag-of-Words (PyTorch)\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UB-v_PAQWrJD",
        "colab_type": "text"
      },
      "source": [
        "The notebook is roughly divided into two sections: pre-processing and the actual model.\n",
        "\n",
        "## Setup and downloading data\n",
        "\n",
        "We use the Kaggle API to download the data. \n",
        "\n",
        "**N.B.** If you want to run the notebook you need to upload a `kaggle.json` file which contains your API credentials. Instructions for downloading the file from Kaggle can be found [here](https://github.com/Kaggle/kaggle-api)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hG0htS1U6osw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# install the kaggle API\n",
        "pip install kaggle -q"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UuOF6emZFysw",
        "colab": {}
      },
      "source": [
        "# data wrangling\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# language model \n",
        "import spacy\n",
        "spacy_en = spacy.load('en')\n",
        "\n",
        "# pytorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils import data\n",
        "\n",
        "from collections import Counter\n",
        "import copy\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q79QeYfz6TU-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CNTJbs7iRrsR",
        "outputId": "0a6d5d8d-489f-4f0d-8d13-2e26e2893ca9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lITfFTkL6taS",
        "colab_type": "code",
        "outputId": "3590c94d-caaa-44d1-a72f-99c23c92387d",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "# upload kaggle.json file\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-11c8629d-a0e1-4950-bf5b-282f8d786014\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-11c8629d-a0e1-4950-bf5b-282f8d786014\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPDGQL0L6xg0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwgL3sGE6zjS",
        "colab_type": "code",
        "outputId": "791e9fb4-4f35-404b-d156-efe5e8dcb9b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "# download the dataset and unzip\n",
        "!kaggle competitions download sentiment-analysis-on-movie-reviews\n",
        "!unzip train.tsv.zip"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "Downloading sampleSubmission.csv to /content\n",
            "  0% 0.00/583k [00:00<?, ?B/s]\n",
            "100% 583k/583k [00:00<00:00, 37.3MB/s]\n",
            "Downloading train.tsv.zip to /content\n",
            "  0% 0.00/1.28M [00:00<?, ?B/s]\n",
            "100% 1.28M/1.28M [00:00<00:00, 86.6MB/s]\n",
            "Downloading test.tsv.zip to /content\n",
            "  0% 0.00/494k [00:00<?, ?B/s]\n",
            "100% 494k/494k [00:00<00:00, 69.1MB/s]\n",
            "Archive:  train.tsv.zip\n",
            "  inflating: train.tsv               \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wlzIl7xMrY51"
      },
      "source": [
        "## Pre-processing \n",
        "\n",
        "The model cannot accept strings as input, thus in this section we convert each element of the dataset into an integer-encoded vector."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZI8hXWE7e9U",
        "colab_type": "text"
      },
      "source": [
        "###  Text processing\n",
        "\n",
        "Descriptions:\n",
        "- `tokenizer`: function that takes as input a string of text and returns a list of tokens \n",
        "- `Vocabularly`: class that stores the vocab found in the dataset and creates a mapping from token to integer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pZuiHLj2WHBy",
        "colab": {}
      },
      "source": [
        "def tokenizer(text): \n",
        "    text = text.lower()\n",
        "    text = re.sub(\"-rrb-\",\"\", text)\n",
        "    text = re.sub(\"-lrb-\",\"\", text)\n",
        "    tokens = spacy_en.tokenizer(text)\n",
        "    #tokens = [tok for tok in tokens if tok.is_stop == False]\n",
        "    tokens = [tok.lemma_ for tok in tokens]\n",
        "    return tokens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_l0ennpbrfrl",
        "colab": {}
      },
      "source": [
        "class Vocabulary:\n",
        "      \n",
        "    def __init__(self, vocabCount, min_freq):\n",
        "        \n",
        "        # N.B. normally 0 would always correspond to a padding token,\n",
        "        # however with our implementation we don't need padding,\n",
        "        # and as such it can be used as an UNK token\n",
        "\n",
        "        # UNK tokens (don't need pad token for bag-of-words)\n",
        "        self.UNK_token = 0\n",
        "        self.vocabCount = vocabCount\n",
        "        self.min_freq = min_freq\n",
        "        # initialize list of words and vocab dictionary\n",
        "        self.wordlist = [\"<unk>\"]\n",
        "        self.word2index = {}\n",
        "        # build vocab\n",
        "        self.build_vocab(vocabCount)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.word2index)\n",
        "\n",
        "    def __getitem__(self, word):\n",
        "        return self.word2index.get(word, 0)\n",
        "\n",
        "    def __iter__(self):\n",
        "        return iter(vocab.word2index)\n",
        "\n",
        "    def build_vocab(self, vocabCount):\n",
        "        # sort vocab s.t. words that occur most frequently added first\n",
        "        svocabCount = {k: v for k, v in reversed(sorted(vocabCount.items(), \n",
        "                                                      key=lambda item: item[1]))}\n",
        "        \n",
        "        for word in svocabCount:\n",
        "            if svocabCount[word] >= self.min_freq:\n",
        "                self.wordlist.append(word)\n",
        "        self.word2index.update({tok: i for i, tok in enumerate(self.wordlist)})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "X7x1zIbDX9Dy"
      },
      "source": [
        "### Loading and processing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0vxFaGmkGHpF",
        "colab": {}
      },
      "source": [
        "train_data = pd.read_csv('/content/train.tsv', sep=\"\\t\", \n",
        "                         encoding=\"utf_8_sig\")\n",
        "\n",
        "phrases = np.array(train_data.iloc[:, 2])\n",
        "target = np.array(train_data.iloc[:, 3])\n",
        "\n",
        "# create train and validation sets\n",
        "X_train , X_val, y_train , y_val = train_test_split(phrases, target, \n",
        "                                                    test_size = 0.2, random_state=42)\n",
        "\n",
        "# create validation and test sets\n",
        "X_val , X_test, y_val , y_test = train_test_split(X_val, y_val, \n",
        "                                                    test_size = 0.4, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dQMnv1F1ZoPh"
      },
      "source": [
        "Convert each string into a list of words, using `tokenizer` function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BU8Ue_D6MiA6",
        "colab": {}
      },
      "source": [
        "X_train = [tokenizer(phrase) for phrase in X_train]\n",
        "X_val = [tokenizer(phrase) for phrase in X_val]\n",
        "X_test = [tokenizer(phrase) for phrase in X_test]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IU3QVOq-OdVU",
        "outputId": "304d52f2-b031-4653-efd5-57403cc99e5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        }
      },
      "source": [
        "print(\"Length of train dataset: {} \\nLength of validation dataset: {} \\nLength of test dataset: {}\".format(len(X_train), len(X_val), len(X_test)))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of train dataset: 124848 \n",
            "Length of validation dataset: 18727 \n",
            "Length of test dataset: 12485\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "P7kkx0UzfFre"
      },
      "source": [
        "### Creating vocabularly"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hmPXl7aGNBh4",
        "colab": {}
      },
      "source": [
        "# go through each token in training set and add to dictionary\n",
        "vocabCount = Counter([item for sublist in X_train for item in sublist])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-VSpYtzQlv-e",
        "colab": {}
      },
      "source": [
        "# use dictionary to build vocab\n",
        "vocab = Vocabulary(vocabCount, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_vsCWWRjZkpV"
      },
      "source": [
        "### Converting tokens to integers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "S3qO5seuNUhu",
        "colab": {}
      },
      "source": [
        "X_trainNum = [torch.tensor([vocab[word] for word in phrase]) for phrase in X_train]\n",
        "X_valNum = [torch.tensor([vocab[word] for word in phrase]) for phrase in X_val]\n",
        "X_testNum = [torch.tensor([vocab[word] for word in phrase]) for phrase in X_test]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GrV5nB4PU3f2",
        "colab_type": "text"
      },
      "source": [
        "Our pre-processing might have resulted in some now empty lists. These can cause problems later so we just fil them with padding (another possibility would be to remove these examples as they contain no useful information)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "H92tsfWHszGf",
        "outputId": "03bd0568-1395-421a-af48-02e8ca0d0654",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# make sure each tensor actually has values\n",
        "for i, el in enumerate(X_trainNum):\n",
        "    if el.nelement() == 0:\n",
        "        print(i)\n",
        "        X_trainNum[i] = torch.tensor([0]).long()\n",
        "\n",
        "# make sure each tensor actually has values\n",
        "for i, el in enumerate(X_valNum):\n",
        "    if el.nelement() == 0:\n",
        "        print(i)\n",
        "        X_valNum[i] = torch.tensor([0]).long()\n",
        "\n",
        "# make sure each tensor actually has values\n",
        "for i, el in enumerate(X_testNum):\n",
        "    if el.nelement() == 0:\n",
        "        print(i)\n",
        "        X_testNum[i] = torch.tensor([0]).long()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "43785\n",
            "7117\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZPRCHd-bZ4Jp"
      },
      "source": [
        "##  Bag of vectors \n",
        "\n",
        "We convert each word in a sentence into an embedding, as each sentence may have a different number of words, we use a pooling operation to convert the variable number of word embeddings into a fixed representation. Options for the pooling operation are `mean`, `sum` and a variety of elementwise operations.\n",
        "\n",
        "Thus, in our model we simply have an embedding layer and a pooling operation, we then feed the resulting representation into an MLP. In PyTorch, there is a function `EmbeddingBag` that implements the embedding and pooling/reduction."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EozVu_o0n_3n"
      },
      "source": [
        "### Custom dataset class and batching function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bcIU7hCQaRc0",
        "colab": {}
      },
      "source": [
        "class WordDataset(data.Dataset):\n",
        "    \n",
        "    def __init__(self, X, y):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "    \n",
        "    def __getitem__(self, idx):  \n",
        "        X = self.X[idx]\n",
        "        Y = self.y[idx]\n",
        "        return X, Y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RwFJvtSlXiJN",
        "colab_type": "text"
      },
      "source": [
        "The `generate_batch` function processes each batch that is returned by the DataLoader."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kqC2vHYjaRha",
        "colab": {}
      },
      "source": [
        "def generate_batch(batch):\n",
        "    \n",
        "    # get data and targets from batch\n",
        "    data = [item[0] for item in batch]\n",
        "    targets = [item[1] for item in batch]\n",
        "    lengths = [len(el) for el in data]\n",
        "    offsets = np.cumsum(lengths)\n",
        "    offsets = np.concatenate([[0], offsets[:-1]])\n",
        "  \n",
        "    return torch.LongTensor(torch.cat(data).long()), torch.Tensor(targets).long(), torch.LongTensor(offsets)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dYnatxHhoYPX",
        "colab": {}
      },
      "source": [
        "trainingset = WordDataset(X_trainNum, y_train)\n",
        "valset = WordDataset(X_valNum, y_val)\n",
        "testset = WordDataset(X_testNum, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kTEWQ12eobmj",
        "colab": {}
      },
      "source": [
        "training_generator = data.DataLoader(trainingset, batch_size=64, collate_fn=generate_batch)\n",
        "val_generator = data.DataLoader(valset, batch_size=len(y_val), collate_fn=generate_batch)\n",
        "test_generator = data.DataLoader(testset, batch_size=len(y_test), collate_fn=generate_batch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wkmdPpexrKcK",
        "colab": {}
      },
      "source": [
        "training_eval = data.DataLoader(trainingset, batch_size=1024, collate_fn = generate_batch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5zqHrSFkoFp5"
      },
      "source": [
        "### Training function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "W3hSRCvPoWTo",
        "colab": {}
      },
      "source": [
        "def train(m, lossFun, optim, scheduler, epochs, train_loader, val_loader, train_eval,\n",
        "          saveModel = False, verbose=False):\n",
        "\n",
        "    print(\"Summary of model\\n\")\n",
        "    print(m)\n",
        "    print(\"\\n\")\n",
        "\n",
        "    # initialize lists to store loss and accuracy\n",
        "    trainLossVec , valLossVec, trainAccuracyVec, valAccuracyVec = [], [], [], []\n",
        "    bestLoss, bestEpoch = 100, 0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        # Set model to training mode\n",
        "        m.train()\n",
        "    \n",
        "        # Loop over each batch from the training set\n",
        "        for batch_idx, (inputs, targets, offsets) in enumerate(train_loader):\n",
        "            \n",
        "            # Zero gradient buffers\n",
        "            optim.zero_grad()\n",
        "            # Foward pass and compute loss on batch\n",
        "            outputs = m(inputs.to(device), offsets.to(device))\n",
        "            batchloss = lossFun(outputs, targets.to(device))\n",
        "            # Backpropagate and update weights\n",
        "            batchloss.backward()\n",
        "            # gradient clipping\n",
        "            #torch.nn.utils.clip_grad_norm_(m.parameters(), 1., norm_type=2)\n",
        "            # optimizer step\n",
        "            optim.step()\n",
        "    \n",
        "        # set model to evaluation mode\n",
        "        m.eval()\n",
        "        with torch.no_grad():\n",
        "\n",
        "            # evaluate model on training and validation data\n",
        "            train_metrics = evaluate(m, train_eval, lossFun)\n",
        "            val_metrics = evaluate(m, val_loader, lossFun)\n",
        "            # update accuracy\n",
        "            trainAccuracyVec.append(train_metrics[\"acc\"])\n",
        "            valAccuracyVec.append(val_metrics[\"acc\"])\n",
        "            # update loss\n",
        "            trainLossVec.append(train_metrics[\"loss\"])\n",
        "            valLossVec.append(val_metrics[\"loss\"])\n",
        "\n",
        "            # opportunity to not include a scheduler\n",
        "            if scheduler != None:\n",
        "                scheduler.step()\n",
        "    \n",
        "            # check if new best for validation accuracy\n",
        "            if valLossVec[-1] < bestLoss:\n",
        "                bestLoss = valLossVec[-1]\n",
        "                bestEpoch = epoch\n",
        "                if saveModel == True:\n",
        "                    torch.save(m.state_dict(), \"bestModel.pt\")\n",
        "                    print(\"New best value for validation loss: Saved model to bestModel.pt\")\n",
        "            \n",
        "            # print information about training progress\n",
        "            if verbose == True:\n",
        "                print((\"Epoch: {} \\t Loss (train): {:.3f} (val): {:.3f} \\t\" +\n",
        "              \"Acc (train) {:.3f} (val): {:.3f}\").format(epoch + 1,\n",
        "                            trainLossVec[-1], valLossVec[-1], trainAccuracyVec[-1], valAccuracyVec[-1]))\n",
        "            # clean up\n",
        "            del inputs, targets, outputs\n",
        "\n",
        "    return trainLossVec, valLossVec, trainAccuracyVec, valAccuracyVec, bestEpoch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B42TNO0AVTZY",
        "colab_type": "text"
      },
      "source": [
        "### Evaluation functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZG5UylwwU3G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def eval_batch(model, batch, lossFun):\n",
        "\n",
        "  inputs, targets, offsets = batch\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    batchsize = len(targets)\n",
        "    logits = model(inputs.to(device), offsets.to(device))\n",
        "    # for loss\n",
        "    lossVal = lossFun(logits, targets.to(device)).item() * batchsize\n",
        "    # for accuracy\n",
        "    _, pred = torch.max(logits.data, 1)\n",
        "    correct = (pred == targets.to(device)).sum().item()\n",
        "\n",
        "  return correct, lossVal"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJ_I0QdPxGzb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, dataLoader, lossFun):\n",
        "\n",
        "  correct = 0\n",
        "  loss = 0\n",
        "  total = 0\n",
        "  for batch in dataLoader:\n",
        "    c, l = eval_batch(model, batch, lossFun)\n",
        "    correct += c\n",
        "    loss += l\n",
        "    total += batch[1].shape[0]\n",
        "\n",
        "  acc = correct/total\n",
        "  loss = loss/total\n",
        "  return {\"acc\": acc, \"loss\": loss}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "t1GjUttBspnL"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "g6IfM4wroJYp",
        "colab": {}
      },
      "source": [
        "class BagofVector(nn.Module):\n",
        "    \n",
        "    def __init__(self, embeddingDIM, hiddenDIM1, hiddenDIM2, \n",
        "               ouputDIM, vocab_size, pooling=\"sum\"):\n",
        "        \n",
        "        super(BagofVector, self).__init__()\n",
        "        self.embedding = nn.EmbeddingBag(vocab_size, embeddingDIM, mode=pooling)\n",
        "        self.linear1 = nn.Linear(embeddingDIM, hiddenDIM1)\n",
        "        self.linear2 = nn.Linear(hiddenDIM1, hiddenDIM2)\n",
        "        self.linear3 = nn.Linear(hiddenDIM2, ouputDIM)\n",
        "        self.dropout = nn.Dropout()\n",
        "        \n",
        "    def forward(self, inputs, offsets):\n",
        "\n",
        "        x = self.embedding(inputs, offsets)\n",
        "        x = self.dropout(F.relu(self.linear1(x)))\n",
        "        x = self.dropout(F.relu(self.linear2(x)))\n",
        "        x = self.linear3(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NZkxVZcQoWZS",
        "colab": {}
      },
      "source": [
        "torch.manual_seed(42)\n",
        "mlp = BagofVector(300, 128, 64, 5, len(vocab), \"sum\").to(device)\n",
        "optimizer = optim.Adam(mlp.parameters(), lr = 1e-4)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.8) \n",
        "loss = nn.CrossEntropyLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "i0iL19ITozfr",
        "outputId": "a08011a1-77b7-44e8-afe0-4509c9812746",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "trainLossVec, valLossVec, trainAccVec, valAccVec, bEpoch = train(mlp, loss, optimizer, scheduler, 50, \n",
        "                                      training_generator, val_generator, \n",
        "                                      training_eval, verbose=True, saveModel=True)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Summary of model\n",
            "\n",
            "BagofVector(\n",
            "  (embedding): EmbeddingBag(12133, 300, mode=sum)\n",
            "  (linear1): Linear(in_features=300, out_features=128, bias=True)\n",
            "  (linear2): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (linear3): Linear(in_features=64, out_features=5, bias=True)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            ")\n",
            "\n",
            "\n",
            "New best value for validation loss: Saved model to bestModel.pt\n",
            "Epoch: 1 \t Loss (train): 1.238 (val): 1.250 \tAcc (train) 0.515 (val): 0.506\n",
            "New best value for validation loss: Saved model to bestModel.pt\n",
            "Epoch: 2 \t Loss (train): 1.186 (val): 1.204 \tAcc (train) 0.524 (val): 0.517\n",
            "New best value for validation loss: Saved model to bestModel.pt\n",
            "Epoch: 3 \t Loss (train): 1.136 (val): 1.160 \tAcc (train) 0.539 (val): 0.531\n",
            "New best value for validation loss: Saved model to bestModel.pt\n",
            "Epoch: 4 \t Loss (train): 1.085 (val): 1.118 \tAcc (train) 0.557 (val): 0.544\n",
            "New best value for validation loss: Saved model to bestModel.pt\n",
            "Epoch: 5 \t Loss (train): 1.040 (val): 1.081 \tAcc (train) 0.573 (val): 0.558\n",
            "New best value for validation loss: Saved model to bestModel.pt\n",
            "Epoch: 6 \t Loss (train): 1.005 (val): 1.054 \tAcc (train) 0.586 (val): 0.571\n",
            "New best value for validation loss: Saved model to bestModel.pt\n",
            "Epoch: 7 \t Loss (train): 0.975 (val): 1.030 \tAcc (train) 0.600 (val): 0.580\n",
            "New best value for validation loss: Saved model to bestModel.pt\n",
            "Epoch: 8 \t Loss (train): 0.948 (val): 1.009 \tAcc (train) 0.610 (val): 0.588\n",
            "New best value for validation loss: Saved model to bestModel.pt\n",
            "Epoch: 9 \t Loss (train): 0.925 (val): 0.991 \tAcc (train) 0.617 (val): 0.596\n",
            "New best value for validation loss: Saved model to bestModel.pt\n",
            "Epoch: 10 \t Loss (train): 0.902 (val): 0.975 \tAcc (train) 0.627 (val): 0.602\n",
            "New best value for validation loss: Saved model to bestModel.pt\n",
            "Epoch: 11 \t Loss (train): 0.886 (val): 0.964 \tAcc (train) 0.634 (val): 0.608\n",
            "New best value for validation loss: Saved model to bestModel.pt\n",
            "Epoch: 12 \t Loss (train): 0.870 (val): 0.952 \tAcc (train) 0.641 (val): 0.613\n",
            "New best value for validation loss: Saved model to bestModel.pt\n",
            "Epoch: 13 \t Loss (train): 0.857 (val): 0.944 \tAcc (train) 0.646 (val): 0.617\n",
            "New best value for validation loss: Saved model to bestModel.pt\n",
            "Epoch: 14 \t Loss (train): 0.844 (val): 0.935 \tAcc (train) 0.651 (val): 0.618\n",
            "New best value for validation loss: Saved model to bestModel.pt\n",
            "Epoch: 15 \t Loss (train): 0.832 (val): 0.927 \tAcc (train) 0.656 (val): 0.624\n",
            "New best value for validation loss: Saved model to bestModel.pt\n",
            "Epoch: 16 \t Loss (train): 0.821 (val): 0.921 \tAcc (train) 0.661 (val): 0.624\n",
            "New best value for validation loss: Saved model to bestModel.pt\n",
            "Epoch: 17 \t Loss (train): 0.812 (val): 0.916 \tAcc (train) 0.664 (val): 0.628\n",
            "New best value for validation loss: Saved model to bestModel.pt\n",
            "Epoch: 18 \t Loss (train): 0.805 (val): 0.911 \tAcc (train) 0.665 (val): 0.629\n",
            "New best value for validation loss: Saved model to bestModel.pt\n",
            "Epoch: 19 \t Loss (train): 0.796 (val): 0.907 \tAcc (train) 0.669 (val): 0.630\n",
            "New best value for validation loss: Saved model to bestModel.pt\n",
            "Epoch: 20 \t Loss (train): 0.788 (val): 0.902 \tAcc (train) 0.674 (val): 0.633\n",
            "New best value for validation loss: Saved model to bestModel.pt\n",
            "Epoch: 21 \t Loss (train): 0.782 (val): 0.899 \tAcc (train) 0.676 (val): 0.634\n",
            "New best value for validation loss: Saved model to bestModel.pt\n",
            "Epoch: 22 \t Loss (train): 0.776 (val): 0.896 \tAcc (train) 0.678 (val): 0.637\n",
            "New best value for validation loss: Saved model to bestModel.pt\n",
            "Epoch: 23 \t Loss (train): 0.771 (val): 0.892 \tAcc (train) 0.680 (val): 0.637\n",
            "New best value for validation loss: Saved model to bestModel.pt\n",
            "Epoch: 24 \t Loss (train): 0.764 (val): 0.889 \tAcc (train) 0.682 (val): 0.640\n",
            "New best value for validation loss: Saved model to bestModel.pt\n",
            "Epoch: 25 \t Loss (train): 0.759 (val): 0.887 \tAcc (train) 0.686 (val): 0.642\n",
            "New best value for validation loss: Saved model to bestModel.pt\n",
            "Epoch: 26 \t Loss (train): 0.754 (val): 0.885 \tAcc (train) 0.688 (val): 0.643\n",
            "New best value for validation loss: Saved model to bestModel.pt\n",
            "Epoch: 27 \t Loss (train): 0.750 (val): 0.883 \tAcc (train) 0.689 (val): 0.643\n",
            "New best value for validation loss: Saved model to bestModel.pt\n",
            "Epoch: 28 \t Loss (train): 0.746 (val): 0.882 \tAcc (train) 0.692 (val): 0.645\n",
            "New best value for validation loss: Saved model to bestModel.pt\n",
            "Epoch: 29 \t Loss (train): 0.742 (val): 0.880 \tAcc (train) 0.692 (val): 0.646\n",
            "New best value for validation loss: Saved model to bestModel.pt\n",
            "Epoch: 30 \t Loss (train): 0.739 (val): 0.879 \tAcc (train) 0.694 (val): 0.646\n",
            "New best value for validation loss: Saved model to bestModel.pt\n",
            "Epoch: 31 \t Loss (train): 0.735 (val): 0.878 \tAcc (train) 0.696 (val): 0.647\n",
            "New best value for validation loss: Saved model to bestModel.pt\n",
            "Epoch: 32 \t Loss (train): 0.732 (val): 0.877 \tAcc (train) 0.697 (val): 0.647\n",
            "New best value for validation loss: Saved model to bestModel.pt\n",
            "Epoch: 33 \t Loss (train): 0.729 (val): 0.874 \tAcc (train) 0.698 (val): 0.647\n",
            "New best value for validation loss: Saved model to bestModel.pt\n",
            "Epoch: 34 \t Loss (train): 0.726 (val): 0.874 \tAcc (train) 0.699 (val): 0.648\n",
            "New best value for validation loss: Saved model to bestModel.pt\n",
            "Epoch: 35 \t Loss (train): 0.724 (val): 0.872 \tAcc (train) 0.700 (val): 0.649\n",
            "Epoch: 36 \t Loss (train): 0.721 (val): 0.872 \tAcc (train) 0.701 (val): 0.649\n",
            "New best value for validation loss: Saved model to bestModel.pt\n",
            "Epoch: 37 \t Loss (train): 0.719 (val): 0.872 \tAcc (train) 0.702 (val): 0.650\n",
            "New best value for validation loss: Saved model to bestModel.pt\n",
            "Epoch: 38 \t Loss (train): 0.717 (val): 0.871 \tAcc (train) 0.703 (val): 0.651\n",
            "New best value for validation loss: Saved model to bestModel.pt\n",
            "Epoch: 39 \t Loss (train): 0.714 (val): 0.871 \tAcc (train) 0.704 (val): 0.650\n",
            "New best value for validation loss: Saved model to bestModel.pt\n",
            "Epoch: 40 \t Loss (train): 0.712 (val): 0.870 \tAcc (train) 0.704 (val): 0.651\n",
            "New best value for validation loss: Saved model to bestModel.pt\n",
            "Epoch: 41 \t Loss (train): 0.711 (val): 0.869 \tAcc (train) 0.705 (val): 0.652\n",
            "New best value for validation loss: Saved model to bestModel.pt\n",
            "Epoch: 42 \t Loss (train): 0.709 (val): 0.869 \tAcc (train) 0.706 (val): 0.652\n",
            "New best value for validation loss: Saved model to bestModel.pt\n",
            "Epoch: 43 \t Loss (train): 0.707 (val): 0.868 \tAcc (train) 0.707 (val): 0.652\n",
            "New best value for validation loss: Saved model to bestModel.pt\n",
            "Epoch: 44 \t Loss (train): 0.706 (val): 0.868 \tAcc (train) 0.707 (val): 0.653\n",
            "New best value for validation loss: Saved model to bestModel.pt\n",
            "Epoch: 45 \t Loss (train): 0.704 (val): 0.867 \tAcc (train) 0.707 (val): 0.652\n",
            "New best value for validation loss: Saved model to bestModel.pt\n",
            "Epoch: 46 \t Loss (train): 0.703 (val): 0.867 \tAcc (train) 0.708 (val): 0.653\n",
            "New best value for validation loss: Saved model to bestModel.pt\n",
            "Epoch: 47 \t Loss (train): 0.701 (val): 0.867 \tAcc (train) 0.709 (val): 0.653\n",
            "New best value for validation loss: Saved model to bestModel.pt\n",
            "Epoch: 48 \t Loss (train): 0.700 (val): 0.866 \tAcc (train) 0.710 (val): 0.653\n",
            "Epoch: 49 \t Loss (train): 0.699 (val): 0.866 \tAcc (train) 0.710 (val): 0.653\n",
            "New best value for validation loss: Saved model to bestModel.pt\n",
            "Epoch: 50 \t Loss (train): 0.698 (val): 0.866 \tAcc (train) 0.711 (val): 0.654\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QvVqaswIW0lh",
        "colab_type": "text"
      },
      "source": [
        "### Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-eKY7MNWxrJH",
        "colab": {}
      },
      "source": [
        "bestModel = copy.deepcopy(mlp)\n",
        "bestModel.load_state_dict(torch.load(\"bestModel.pt\"))\n",
        "bestModel = bestModel.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "teQre_3UwmnV",
        "colab": {}
      },
      "source": [
        "train_metrics = evaluate(bestModel, training_eval, loss)\n",
        "val_metrics = evaluate(bestModel, val_generator, loss)\n",
        "test_metrics = evaluate(bestModel, test_generator, loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "08nvxbcEyEDY",
        "outputId": "b3cb3013-337c-4f69-8604-4f64160a2008",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115
        }
      },
      "source": [
        "print(\"Train metrics: \\n{}\".format(train_metrics))\n",
        "print(\"Val metrics: \\n{}\".format(val_metrics))\n",
        "print(\"Test metrics: \\n{}\".format(test_metrics))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train metrics: \n",
            "{'acc': 0.7106721773676791, 'loss': 0.6975671537454413}\n",
            "Val metrics: \n",
            "{'acc': 0.653655150317723, 'loss': 0.8656288981437683}\n",
            "Test metrics: \n",
            "{'acc': 0.6526231477773328, 'loss': 0.8659286499023438}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PW7pV3d4cQU",
        "colab_type": "code",
        "outputId": "8f7b4841-4874-4517-a715-7e1cb3b6da62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        }
      },
      "source": [
        "matplotlib.rcParams['axes.spines.top'] = False\n",
        "matplotlib.rcParams['axes.spines.right'] = False\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12,5))\n",
        "\n",
        "ax1.plot(range(len(valAccVec)), valAccVec, label = \"Validation\")\n",
        "ax1.plot(range(len(trainAccVec)), trainAccVec, label = \"Train\")\n",
        "ax1.grid(True, alpha=0.4)\n",
        "ax1.set_title(\"Accuracy\")\n",
        "ax1.legend()\n",
        "ax2.plot(range(len(valLossVec)), valLossVec, label = \"Validation\")\n",
        "ax2.plot(range(len(trainLossVec)), trainLossVec, label = \"Train\")\n",
        "ax2.grid(True, alpha=0.4)\n",
        "ax2.set_title(\"Loss\")\n",
        "ax2.legend()\n",
        "plt.show()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "urWAItgy0p7O",
        "colab_type": "text"
      },
      "source": [
        "## Using pre-trained embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8AMuV0w0tvw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "outputId": "939000df-2764-43d6-9350-72eca87b92da"
      },
      "source": [
        "# download glove embeddings\n",
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove*.zip\n",
        "print('Indexing word vectors.')\n",
        "embeddings_index = {}\n",
        "f = open('glove.6B.300d.txt', encoding='utf-8')\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "print('Found {} word vectors.'.format(len(embeddings_index)))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-22 17:42:42--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2020-04-22 17:42:42--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2020-04-22 17:42:42--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  2.07MB/s    in 6m 27s  \n",
            "\n",
            "2020-04-22 17:49:09 (2.13 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n",
            "Indexing word vectors.\n",
            "Found 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRYjl9JM1EFn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "f344df10-d4e5-4918-cecf-00eabe5ee033"
      },
      "source": [
        "# iterate through each word in the vocabularly\n",
        "# if there exists a word embedding insert it,\n",
        "# else use a sample from a random normal\n",
        "matrix_len = len(vocab)\n",
        "weights_matrix = np.zeros((matrix_len, 300))\n",
        "words_notfound = 0\n",
        "\n",
        "for i, word in enumerate(vocab):\n",
        "    try: \n",
        "        weights_matrix[i] = embeddings_index[word]\n",
        "        \n",
        "    # if there is no embedding for the given word\n",
        "    # create vector sampled from random normal\n",
        "\n",
        "    # a advantage of updating the weights of the\n",
        "    # embedding layer as part of training, is that\n",
        "    # an embedding will be learnt for these words \n",
        "    except KeyError:\n",
        "\n",
        "        weights_matrix[i] = np.random.normal(scale=0.5, size=(300, ))\n",
        "        words_notfound += 1\n",
        "\n",
        "# clean up\n",
        "#del embeddings_index\n",
        "\n",
        "print(\"Words not found: {}\".format(words_notfound))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Words not found: 440\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOAYiDg41X30",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# slightly rewrite model class\n",
        "# enables to easily set different learning rates for parameter groups\n",
        "class BagofVector(nn.Module):\n",
        "    \n",
        "    def __init__(self, embeddingDIM, hiddenDIM1, hiddenDIM2, \n",
        "               ouputDIM, vocab_size, pooling=\"sum\"):\n",
        "        \n",
        "        super(BagofVector, self).__init__()\n",
        "\n",
        "        self.embedding = nn.EmbeddingBag(vocab_size, embeddingDIM, mode=pooling)\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(embeddingDIM, hiddenDIM1),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(hiddenDIM1, hiddenDIM2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(hiddenDIM2, ouputDIM)\n",
        "        )\n",
        "\n",
        "    def forward(self, inputs, offsets):\n",
        "\n",
        "        x = self.embedding(inputs, offsets)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pT666aAa1Sbb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.manual_seed(42)\n",
        "mlp = BagofVector(300, 128, 64, 5, len(vocab), \"sum\").to(device)\n",
        "mlp.embedding.weight.data.copy_(torch.from_numpy(weights_matrix))\n",
        "optimizer = optim.Adam([\n",
        "                {'params': mlp.fc.parameters(), 'lr': 2e-4},\n",
        "                {'params': mlp.embedding.weight, 'lr': 1e-5}\n",
        "            ])\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=6, gamma=0.8) \n",
        "loss = nn.CrossEntropyLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-M5z8WO3DN6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "541728a6-319e-449f-e6f8-59dd23aa96f6"
      },
      "source": [
        "trainLossVec, valLossVec, trainAccVec, valAccVec, bEpoch = train(mlp, loss, optimizer, scheduler, 50, \n",
        "                                      training_generator, val_generator, \n",
        "                                      training_eval, verbose=True, saveModel=True)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Summary of model\n",
            "\n",
            "BagofVector(\n",
            "  (embedding): EmbeddingBag(12133, 300, mode=sum)\n",
            "  (fc): Sequential(\n",
            "    (0): Linear(in_features=300, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=64, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Dropout(p=0.5, inplace=False)\n",
            "    (6): Linear(in_features=64, out_features=5, bias=True)\n",
            "  )\n",
            ")\n",
            "\n",
            "\n",
            "New best value for validation loss: Saved model to bestModel.pt\n",
            "Epoch: 1 \t Loss (train): 1.002 (val): 1.010 \tAcc (train) 0.588 (val): 0.582\n",
            "New best value for validation loss: Saved model to bestModel.pt\n",
            "Epoch: 2 \t Loss (train): 0.954 (val): 0.965 \tAcc (train) 0.602 (val): 0.598\n",
            "New best value for validation loss: Saved model to bestModel.pt\n",
            "Epoch: 3 \t Loss (train): 0.931 (val): 0.946 \tAcc (train) 0.610 (val): 0.603\n",
            "New best value for validation loss: Saved model to bestModel.pt\n",
            "Epoch: 4 \t Loss (train): 0.912 (val): 0.933 \tAcc (train) 0.614 (val): 0.604\n",
            "New best value for validation loss: Saved model to bestModel.pt\n",
            "Epoch: 5 \t Loss (train): 0.898 (val): 0.922 \tAcc (train) 0.619 (val): 0.607\n",
            "New best value for validation loss: Saved model to bestModel.pt\n",
            "Epoch: 6 \t Loss (train): 0.884 (val): 0.912 \tAcc (train) 0.626 (val): 0.614\n",
            "New best value for validation loss: Saved model to bestModel.pt\n",
            "Epoch: 7 \t Loss (train): 0.873 (val): 0.904 \tAcc (train) 0.630 (val): 0.616\n",
            "New best value for validation loss: Saved model to bestModel.pt\n",
            "Epoch: 8 \t Loss (train): 0.862 (val): 0.897 \tAcc (train) 0.636 (val): 0.621\n",
            "New best value for validation loss: Saved model to bestModel.pt\n",
            "Epoch: 9 \t Loss (train): 0.853 (val): 0.892 \tAcc (train) 0.639 (val): 0.625\n",
            "New best value for validation loss: Saved model to bestModel.pt\n",
            "Epoch: 10 \t Loss (train): 0.846 (val): 0.886 \tAcc (train) 0.644 (val): 0.628\n",
            "New best value for validation loss: Saved model to bestModel.pt\n",
            "Epoch: 11 \t Loss (train): 0.835 (val): 0.880 \tAcc (train) 0.646 (val): 0.626\n",
            "New best value for validation loss: Saved model to bestModel.pt\n",
            "Epoch: 12 \t Loss (train): 0.829 (val): 0.876 \tAcc (train) 0.649 (val): 0.630\n",
            "New best value for validation loss: Saved model to bestModel.pt\n",
            "Epoch: 13 \t Loss (train): 0.821 (val): 0.872 \tAcc (train) 0.652 (val): 0.632\n",
            "New best value for validation loss: Saved model to bestModel.pt\n",
            "Epoch: 14 \t Loss (train): 0.813 (val): 0.866 \tAcc (train) 0.657 (val): 0.636\n",
            "New best value for validation loss: Saved model to bestModel.pt\n",
            "Epoch: 15 \t Loss (train): 0.808 (val): 0.865 \tAcc (train) 0.657 (val): 0.634\n",
            "New best value for validation loss: Saved model to bestModel.pt\n",
            "Epoch: 16 \t Loss (train): 0.802 (val): 0.861 \tAcc (train) 0.660 (val): 0.638\n",
            "New best value for validation loss: Saved model to bestModel.pt\n",
            "Epoch: 17 \t Loss (train): 0.797 (val): 0.859 \tAcc (train) 0.663 (val): 0.640\n",
            "New best value for validation loss: Saved model to bestModel.pt\n",
            "Epoch: 18 \t Loss (train): 0.792 (val): 0.857 \tAcc (train) 0.664 (val): 0.639\n",
            "New best value for validation loss: Saved model to bestModel.pt\n",
            "Epoch: 19 \t Loss (train): 0.785 (val): 0.852 \tAcc (train) 0.669 (val): 0.643\n",
            "New best value for validation loss: Saved model to bestModel.pt\n",
            "Epoch: 20 \t Loss (train): 0.781 (val): 0.852 \tAcc (train) 0.670 (val): 0.642\n",
            "New best value for validation loss: Saved model to bestModel.pt\n",
            "Epoch: 21 \t Loss (train): 0.777 (val): 0.850 \tAcc (train) 0.670 (val): 0.643\n",
            "New best value for validation loss: Saved model to bestModel.pt\n",
            "Epoch: 22 \t Loss (train): 0.773 (val): 0.849 \tAcc (train) 0.672 (val): 0.643\n",
            "Epoch: 23 \t Loss (train): 0.771 (val): 0.849 \tAcc (train) 0.672 (val): 0.645\n",
            "New best value for validation loss: Saved model to bestModel.pt\n",
            "Epoch: 24 \t Loss (train): 0.765 (val): 0.844 \tAcc (train) 0.675 (val): 0.646\n",
            "New best value for validation loss: Saved model to bestModel.pt\n",
            "Epoch: 25 \t Loss (train): 0.762 (val): 0.843 \tAcc (train) 0.677 (val): 0.649\n",
            "New best value for validation loss: Saved model to bestModel.pt\n",
            "Epoch: 26 \t Loss (train): 0.757 (val): 0.840 \tAcc (train) 0.680 (val): 0.650\n",
            "New best value for validation loss: Saved model to bestModel.pt\n",
            "Epoch: 27 \t Loss (train): 0.756 (val): 0.840 \tAcc (train) 0.680 (val): 0.650\n",
            "New best value for validation loss: Saved model to bestModel.pt\n",
            "Epoch: 28 \t Loss (train): 0.753 (val): 0.839 \tAcc (train) 0.681 (val): 0.648\n",
            "New best value for validation loss: Saved model to bestModel.pt\n",
            "Epoch: 29 \t Loss (train): 0.750 (val): 0.837 \tAcc (train) 0.683 (val): 0.651\n",
            "Epoch: 30 \t Loss (train): 0.747 (val): 0.839 \tAcc (train) 0.683 (val): 0.650\n",
            "New best value for validation loss: Saved model to bestModel.pt\n",
            "Epoch: 31 \t Loss (train): 0.744 (val): 0.836 \tAcc (train) 0.685 (val): 0.650\n",
            "New best value for validation loss: Saved model to bestModel.pt\n",
            "Epoch: 32 \t Loss (train): 0.740 (val): 0.835 \tAcc (train) 0.686 (val): 0.652\n",
            "New best value for validation loss: Saved model to bestModel.pt\n",
            "Epoch: 33 \t Loss (train): 0.738 (val): 0.835 \tAcc (train) 0.687 (val): 0.653\n",
            "New best value for validation loss: Saved model to bestModel.pt\n",
            "Epoch: 34 \t Loss (train): 0.736 (val): 0.833 \tAcc (train) 0.689 (val): 0.653\n",
            "Epoch: 35 \t Loss (train): 0.735 (val): 0.835 \tAcc (train) 0.689 (val): 0.653\n",
            "New best value for validation loss: Saved model to bestModel.pt\n",
            "Epoch: 36 \t Loss (train): 0.733 (val): 0.832 \tAcc (train) 0.689 (val): 0.654\n",
            "Epoch: 37 \t Loss (train): 0.729 (val): 0.832 \tAcc (train) 0.691 (val): 0.655\n",
            "New best value for validation loss: Saved model to bestModel.pt\n",
            "Epoch: 38 \t Loss (train): 0.727 (val): 0.831 \tAcc (train) 0.693 (val): 0.654\n",
            "New best value for validation loss: Saved model to bestModel.pt\n",
            "Epoch: 39 \t Loss (train): 0.726 (val): 0.830 \tAcc (train) 0.693 (val): 0.655\n",
            "Epoch: 40 \t Loss (train): 0.725 (val): 0.831 \tAcc (train) 0.694 (val): 0.655\n",
            "Epoch: 41 \t Loss (train): 0.724 (val): 0.831 \tAcc (train) 0.695 (val): 0.656\n",
            "New best value for validation loss: Saved model to bestModel.pt\n",
            "Epoch: 42 \t Loss (train): 0.721 (val): 0.829 \tAcc (train) 0.695 (val): 0.656\n",
            "New best value for validation loss: Saved model to bestModel.pt\n",
            "Epoch: 43 \t Loss (train): 0.719 (val): 0.828 \tAcc (train) 0.697 (val): 0.657\n",
            "Epoch: 44 \t Loss (train): 0.718 (val): 0.829 \tAcc (train) 0.697 (val): 0.657\n",
            "New best value for validation loss: Saved model to bestModel.pt\n",
            "Epoch: 45 \t Loss (train): 0.717 (val): 0.828 \tAcc (train) 0.697 (val): 0.656\n",
            "New best value for validation loss: Saved model to bestModel.pt\n",
            "Epoch: 46 \t Loss (train): 0.715 (val): 0.828 \tAcc (train) 0.698 (val): 0.657\n",
            "New best value for validation loss: Saved model to bestModel.pt\n",
            "Epoch: 47 \t Loss (train): 0.714 (val): 0.827 \tAcc (train) 0.698 (val): 0.658\n",
            "Epoch: 48 \t Loss (train): 0.713 (val): 0.828 \tAcc (train) 0.699 (val): 0.658\n",
            "Epoch: 49 \t Loss (train): 0.711 (val): 0.828 \tAcc (train) 0.700 (val): 0.658\n",
            "New best value for validation loss: Saved model to bestModel.pt\n",
            "Epoch: 50 \t Loss (train): 0.710 (val): 0.827 \tAcc (train) 0.700 (val): 0.660\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWdTWDv13DkQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bestModel = copy.deepcopy(mlp)\n",
        "bestModel.load_state_dict(torch.load(\"bestModel.pt\"))\n",
        "bestModel = bestModel.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpMHvKeg5BnT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_metrics = evaluate(bestModel, training_eval, loss)\n",
        "val_metrics = evaluate(bestModel, val_generator, loss)\n",
        "test_metrics = evaluate(bestModel, test_generator, loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkXFrdeo5CRS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115
        },
        "outputId": "017265a3-7e74-4878-c459-094a7ab00a94"
      },
      "source": [
        "print(\"Train metrics: \\n{}\".format(train_metrics))\n",
        "print(\"Val metrics: \\n{}\".format(val_metrics))\n",
        "print(\"Test metrics: \\n{}\".format(test_metrics))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train metrics: \n",
            "{'acc': 0.6997388824810971, 'loss': 0.7096437430833985}\n",
            "Val metrics: \n",
            "{'acc': 0.6600096117904629, 'loss': 0.8274296522140503}\n",
            "Test metrics: \n",
            "{'acc': 0.6551862234681618, 'loss': 0.8251258730888367}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}